{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분리(Splitting Data)\n",
    "\n",
    "- 머신 러닝(딥 러닝) 모델에 데이터를 훈련시키기 위해서는 데이터를 적절히 분리하는 작업이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 지도 학습(Supervised Learning)\n",
    "\n",
    "- 지도 학습의 훈련 데이터는 문제지를 연상케 합니다. \n",
    "- 지도 학습의 훈련 데이터는 정답이 무엇인지 맞춰 하는 '문제'에 해당되는 데이터와 레이블( label )이라고 부르는 '정답'이 적혀있는 데이터로 구성되어 있습니다. \n",
    "- 기계는 정답이 적혀져 있는 문제지를 문제와 정답을 함께 보면서 열심히 공부하고, 향후에 정답이 없는 문제에 대해서도 정답을 잘 예측해야 합니다.\n",
    "\n",
    "\n",
    "- 예로 스팸 메일 분류기를 만들기 위한 데이터같은 경우에는 메일의 내용과 해당 메일이 정상 메일인지, 스팸 메일인지 적혀있는 레이블로 구성되어져 있습니다. \n",
    "- 아래와 같은 형식의 데이터가 약 20,000개 있다고 가정\n",
    "\n",
    "\n",
    "|텍스트(메일의 내용)|레이블(스팸 여부)|\n",
    "|:---|:---|\n",
    "|당신에게 드리는 마지막 혜택! ...|스팸 메일|\n",
    "|내일 뵐 수 있을지 확인 부탁...|정상 메일|\n",
    "|...|...|\n",
    "|(광고) 멋있어질 수 있는...|스팸 메일|\n",
    "\n",
    "\n",
    "- 기계를 가르치기 위해서 데이터를 총 4개로 나눕니다. \n",
    "- 우선 메일의 내용이 담긴 첫번째 열을 X에 저장합니다. 그리고 메일이 스팸인지 정상인지 정답이 적혀있는 두번째 열을 y에 저장합니다. 이제 문제지에 해당되는 20,000개의 X와 정답지에 해당되는 20,000개의 y가 생겼습니다\n",
    "- X와 y에 대해서 일부 데이터를 또 다시 분리합니다. \n",
    "- 이는 문제지를 다 공부하고나서 실력을 평가하기 위해서 시험(Test)용으로 일부로 일부 문제와 정답지를 빼놓는 것입니다. \n",
    "- 여기서는 2,000개를 분리한다고 가정하겠습니다. 이 때, 분리시에는 여전히 X와 y의 맵핑 관계를 유지해야 합니다. \n",
    "- 어떤 X(문제)에 대한 어떤 y(정답)인지 바로 찾을 수 있어야 합니다. 이렇게 되면 학습용에 해당되는 18,000개의 X, y의 쌍과 시험용에 해당되는 2000개의 X, y의 쌍이 생깁니다\n",
    "\n",
    "\n",
    "<훈련 데이터>  \n",
    "X_train : 문제지 데이터  \n",
    "y_train : 문제지에 대한 정답 데이터.  \n",
    "  \n",
    "<테스트 데이터>  \n",
    "X_test : 시험지 데이터.  \n",
    "y_test : 시험지에 대한 정답 데이터.  \n",
    "  \n",
    "- X_train과 y_train에 대해서 학습을 합니다. \n",
    "- 기계는 현 상태에서는 정답지인 y_train을 볼 수 있기 때문에 18,000개의 문제지 X_train을 보면서 어떤 메일 내용일 때 정상 메일인지 스팸 메일인지를 열심히 규칙을 도출해나가면서 정리해나갑니다. \n",
    "- 그리고 학습을 다 한 기계에게 y_test는 보여주지 않고, X_test에 대해서 정답을 예측하게 합니다. \n",
    "- 그리고 기계가 예측한 답과 실제 정답인 y_test를 비교하면서 기계가 정답을 얼마나 맞췄는지를 평가합니다. \n",
    "- 이 수치가 기계의 정확도(Accuracy)가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. X와 y분리\n",
    "\n",
    "### 1) zip 함수를 이용하여 분리\n",
    "\n",
    "- zip()함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 합니다. \n",
    "- 리스트의 리스트 구성에서 zip 함수는 X와 y를 분리하는데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "X,y = zip(['a', 1], ['b', 2], ['c', 3])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터에서 첫번째로 등장한 원소들끼리 묶이고, 두번째로 등장한 원소들끼리 묶인 것\n",
    "sequences=[['a', 1], ['b', 2], ['c', 3]] # 리스트의 리스트 또는 행렬 또는 2D 텐서.\n",
    "X,y = zip(*sequences) # *를 추가\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터프레임을 이용하여 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>메일 본문</th>\n",
       "      <th>스팸 메일 유무</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당신에게 드리는 마지막 혜택!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내일 뵐 수 있을지 확인 부탁드...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>도연씨. 잘 지내시죠? 오랜만입...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(광고) AI로 주가를 예측할 수 있다!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    메일 본문  스팸 메일 유무\n",
       "0        당신에게 드리는 마지막 혜택!         1\n",
       "1    내일 뵐 수 있을지 확인 부탁드...         0\n",
       "2    도연씨. 잘 지내시죠? 오랜만입...         0\n",
       "3  (광고) AI로 주가를 예측할 수 있다!         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values = [['당신에게 드리는 마지막 혜택!', 1],\n",
    "['내일 뵐 수 있을지 확인 부탁드...', 0],\n",
    "['도연씨. 잘 지내시죠? 오랜만입...', 0],\n",
    "['(광고) AI로 주가를 예측할 수 있다!', 1]]\n",
    "columns = ['메일 본문', '스팸 메일 유무']\n",
    "\n",
    "df = pd.DataFrame(values, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임은 열의 이름으로 각 열에 접근이 가능하므로, 이를 이용하면 손쉽게 X 데이터와 y 데이터를 분리\n",
    "X=df['메일 본문']\n",
    "y=df['스팸 메일 유무']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          당신에게 드리는 마지막 혜택!\n",
      "1      내일 뵐 수 있을지 확인 부탁드...\n",
      "2      도연씨. 잘 지내시죠? 오랜만입...\n",
      "3    (광고) AI로 주가를 예측할 수 있다!\n",
      "Name: 메일 본문, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "Name: 스팸 메일 유무, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) NumPy를 이용하여 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "ar = np.arange(0,16).reshape((4,4))\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 4  5  6]\n",
      " [ 8  9 10]\n",
      " [12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "X=ar[:, :3]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  7 11 15]\n"
     ]
    }
   ],
   "source": [
    "y=ar[:,3]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 테스트 데이터 분리\n",
    "\n",
    "- 이미 X와 y가 분리된 데이터에 대해서 테스트 데이터를 분리하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 사이킷 런을 이용하여 분리\n",
    "\n",
    "- 훈련 데이터와 테스트 데이터를 유용하게 나눌 수 있는 하나의 방법\n",
    "- 사이킷 런은 학습용 테스트와 테스트용 데이터를 분리하게 해주는 train_test_split를 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X : 독립 변수 데이터. (배열이나 데이터프레임)  \n",
    "y : 종속 변수 데이터. 레이블 데이터.  \n",
    "test_size : 테스트용 데이터 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.  \n",
    "train_size : 학습용 데이터의 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.  \n",
    "(test_size와 train_size 중 하나만 기재해도 가능)  \n",
    "random_state : 난수 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "# 실습을 위해 임의로 X와 y가 이미 분리 된 데이터를 생성\n",
    "print(X)\n",
    "print(list(y)) #레이블 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)\n",
    "#3분의 1만 test 데이터로 지정.\n",
    "#random_state 지정으로 인해 순서가 섞인 채로 훈련 데이터와 테스트 데이터가 나눠진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 수동으로 분리\n",
    "\n",
    "- 데이터를 분리하는 방법 중 하나는 수동으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.arange(0,24).reshape((12,2)), range(12)\n",
    "# 실습을 위해 임의로 X와 y가 이미 분리 된 데이터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [20 21]\n",
      " [22 23]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 이제 훈련 데이터의 개수와 테스트 데이터의 개수를 정해보겠습니다. \n",
    "# n_of_train은 훈련 데이터의 개수를 의미하며, n_of_test는 테스트 데이터의 개수를 의미합니다.\n",
    "n_of_train = int(len(X) * 0.8) # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다.\n",
    "n_of_test = int(len(X) - n_of_train) # 전체 길이에서 80%에 해당하는 길이를 뺀다.\n",
    "print(n_of_train)\n",
    "print(n_of_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주의할 점은 아직 훈련 데이터와 테스트 데이터를 나눈 것이 아니라, 이 두 개의 개수를 몇 개로 할지 정하기만 한 상태\n",
    "\n",
    "- n_of_train을 len(X) * 0.8로 구했듯이 n_of_test 또한 len(X) * 0.2로 계산하면 되지 않을까라고 생각할 수 있지만, \n",
    "- 그렇게 할 경우에는 데이터에 누락이 발생합니다. \n",
    "- 예를 들어서 전체 데이터의 개수가 4,518이라고 가정했을 때 4,518의 80%의 값은 3,614.4로 소수점을 내리면 3,614가 됩니다. \n",
    "- 또한 4,518의 20%의 값은 903.6으로 소수점을 내리면 903이 됩니다. \n",
    "- 그리고 3,614 + 903 = 4517이므로 데이터 1개가 누락된 것을 알 수 있습니다. \n",
    "- 그러므로 어느 한 쪽을 먼저 계산하고 그 값만큼 제외하는 방식으로 계산해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[n_of_train:] #전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "y_test = y[n_of_train:] #전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "X_train = X[:n_of_train] #전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
    "y_train = y[:n_of_train] #전체 데이터 중에서 80%만큼 앞의 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "[9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "# 실제로 데이터를 나눌 때도 n_of_train와 같이 하나의 변수만 사용하면 데이터의 누락을 방지할 수 있습니다. \n",
    "# 앞에서 구한 데이터의 개수만큼 훈련 데이터와 테스트 데이터를 분할합니다.\n",
    "print(X_test)\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀(Linear Regression)\n",
    "\n",
    "시험 공부하는 시간을 늘리면 늘릴 수록 성적이 잘 나옵니다. 하루에 걷는 횟수를 늘릴 수록, 몸무게는 줄어듭니다. \n",
    "집의 평수가 클수록, 집의 매매 가격은 비싼 경향이 있습니다. \n",
    "이는 수학적으로 생각해보면 어떤 요인의 수치에 따라서 특정 요인의 수치가 영향을 받고있다고 말할 수 있습니다. \n",
    "조금 더 수학적인 표현을 써보면 어떤 변수의 값에 따라서 특정 변수의 값이 영향을 받고 있다고 볼 수 있습니다. \n",
    "다른 변수의 값을 변하게하는 변수를 x, 변수 x에 의해서 값이 종속적으로 변하는 변수 y라고 해봅시다.\n",
    "\n",
    "\n",
    "이때 변수 x의 값은 독립적으로 변할 수 있는 것에 반해, y값은 계속해서 x의 값에 의해서, \n",
    "종속적으로 결정되므로 x를 독립 변수, y를 종속 변수라고도 합니다. \n",
    "\n",
    "선형 회귀는 한 개 이상의 독립 변수 x와 y의 선형 관계를 모델링합니다. \n",
    "만약, 독립 변수 x가 1개라면 단순 선형 회귀라고 합니다.\n",
    "\n",
    "### 1) 단순 선형 회귀 분석(Simple Linear Regression Analysis)\n",
    "\n",
    "\\begin{equation*}\n",
    "    y = WX + b\n",
    "\\end{equation*}\n",
    "\n",
    "- 위의 수식은 단순 선형 회귀의 수식을 보여줍니다.\n",
    "- 독립 변수 X와 곱해지는 값 W를 머신 러닝에서는 가중치(weight), 별도로 더해지는 값 b를 편향(bias)이라고 합니다. - 직선의 방정식에서는 각각 직선의 기울기와 절편을 의미합니다. \n",
    "- W와 b가 없이 y와 X란 수식은 y는 X와 같다는 하나의 식밖에 표현하지 못합니다. 그래프 상으로 말하면, 하나의 직선밖에 표현하지 못합니다.\n",
    "\n",
    "### 다중 선형 회귀 분석(Multiple Linear Regression Analysis)\n",
    "\n",
    "\\begin{equation*}\n",
    "    y = W_1X_1 + W_2X_2 + ... + W_nX_n + b\n",
    "\\end{equation*}\n",
    "\n",
    "- 집의 매매 가격은 단순히 집의 평수가 크다고 결정되는 게 아니라 집의 층의 수, 방의 개수, 지하철 역과의 거리와도 영향이 있는 것 같습니다. 다수의 요소를 가지고 집의 매매 가격을 예측해보고 싶습니다.\n",
    "- y는 여전히 1개이지만 이제 x는 1개가 아니라 여러 개가 되었습니다. 이제 이를 다중 선형 회귀 분석이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 가설(Hypothesis) 세우기\n",
    "\n",
    "- 단순 선형 회귀를 가지고 문제\n",
    "- 어떤 학생의 공부 시간에 따라서 다음과 같은 점수를 얻었다는 데이터가 있습니다.\n",
    "\n",
    "|hours(x)|score(y)|\n",
    "|:---|:---|\n",
    "|2|25|\n",
    "|3|50|\n",
    "|4|42|\n",
    "|5|61|\n",
    "\n",
    "![alt text]( hypothesis_1.png )\n",
    "\n",
    "- 알고있는 데이터로부터 x와 y의 관계를 유추하고, 이 학생이 6시간, 7시간, 8시간을 공부하였을 때의 성적을 예측해보고 싶습니다. \n",
    "- x와 y의 관계를 유추하기 위해서 수학적으로 식을 세워보게 되는데 머신 러닝에서는 이러한 식을 가설(Hypothesis)이라고 합니다. \n",
    "- 아래의 H(x)에서 H는 Hypothesis를 의미합니다. 사실 선형 회귀의 가설은 이미 아래와 같이 널리 알려져있습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    H( X ) = WX + b\n",
    "\\end{equation*}\n",
    "\n",
    "![alt text]( hypothesis_2.png )\n",
    "\n",
    "- 위의 그림은 W와 b의 값에 따라서 천차만별로 그려지는 직선의 모습을 보여줍니다. \n",
    "- 위의 가설에서 W는 직선의 기울기이고 b는 절편으로 직선을 표현함을 알 수 있습니다. \n",
    "- 결국 선형 회귀는 주어진 데이터로부터 y와 X의 관계를 가장 잘 나타내는 직선을 그리는 일을 말합니다. \n",
    "- 그리고 어떤 직선인지 결정하는 것은 W와 b의 값이므로 선형 회귀에서 해야할 일은 결국 적절한 W와 b를 찾아내는 일이 됩니다.  \n",
    "  \n",
    "  \n",
    "- 아직은 방법을 모르지만, 어떤 방법을 사용하여 적절한 W와 b의 값을 찾은 덕택에 y와 x의 관계를 가장 잘 나타내는 직선을 위의 좌표 평면 상에서 그렸다고 한 번 가정해보겠습니다. \n",
    "- 이 직선을 x가 6일때, 7일때, 8일때에 대해서도 계속해서 직선을 그저 이어그린다면 이 학생이 6시간을 공부했을 때, 7시간을 공부했을 때, 8시간을 공부했을 때의 예상 점수를 말할 수 있게 됩니다. 왜냐면 x가 각각 6일 때, 7일 때, 8일 때의 y값을 확인하면 되기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 비용 함수(Cost function) : 평균 제곱 오차(MSE)\n",
    "\n",
    "- 앞서 주어진 데이터에서 X와 y의 관계를 W와 b를 이용하여 식을 세우는 일을 가설이라고 언급했습니다. \n",
    "- 그리고 이제 해야할 일은 문제에 대한 규칙을 가장 잘 표현하는 W와 b를 찾는 일입니다. \n",
    "- 머신 러닝은 W와 b를 찾기 위해서 실제값과 가설로부터 얻은 예측값의 오차를 계산하는 식을 세우고, 이 식의 값을 최소화하는 최적의 W와 b를 찾아냅니다.\n",
    "\n",
    "\n",
    "- 이 때 실제값과 예측값에 대한 오차에 대한 식을 목적 함수(Objective function) 또는 비용 함수(Cost function) 또는 손실 함수(Loss function)라고 합니다. \n",
    "- 함수의 값을 최소화하거나, 최대화하거나 하는 목적을 가진 함수를 목적 함수(Objective function)라고 합니다. \n",
    "- 그리고 값을 최소화하려고 하면 이를 비용 함수(Cost function) 또는 손실 함수(Loss function)라고 합니다. \n",
    "\n",
    "\n",
    "- 비용 함수는 단순히 실제값과 예측값에 대한 오차를 표현하면 되는 것이 아니라, \n",
    "- 예측값의 오차를 줄이는 일에 최적화 된 식이어야 합니다. \n",
    "- 회귀 문제의 경우에는 주로 평균 제곱 오차(Mean Squared Error, MSE)가 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text]( cost_function.png )\n",
    "\n",
    "- 위의 그래프에 임의의 W의 값 13과 임의의 b의 값 1을 가진 직선을 그렸습니다. \n",
    "- 임의로 그린 직선으로 정답이 아닙니다. \n",
    "- 이제 이 직선으로부터 서서히 W와 b의 값을 바꾸면서 정답인 직선을 찾아내야 합니다.\n",
    "\n",
    "\n",
    "- 사실 y와 X의 관계를 가장 잘 나타내는 직선을 그린다는 것은 위의 그림에서 모든 점들과 위치적으로 가장 가까운 직선을 그린다는 것과 같습니다. \n",
    "- 이제 오차(error)를 정의, 오차는 주어진 데이터에서 각 x에서의 실제값 y와 위의 직선에서 예측하고 있는 H(x)값의 차이를 말합니다. \n",
    "- 즉, 위의 그림에서 ↕는 각 점에서의 오차의 크기를 보여줍니다. \n",
    "- 오차를 줄여가면서 W와 b의 값을 찾아내기 위해서는 전체 오차의 크기를 구해야 합니다.\n",
    "\n",
    "\n",
    "- 오차의 크기를 측정하기 위한 가장 기본적인 방법은 각 오차를 모두 더하는 방법이 있습니다. \n",
    "- 위의 y=13x+1 직선이 예측한 예측값을 각각 실제값으로부터 오차를 계산하여 표를 만들어보면 아래와 같습니다.\n",
    "\n",
    "|hours(x)|2|3|4|5|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|실제값|25|50|42|61|\n",
    "|예측값|27|40|53|66|\n",
    "|오차|-2|10|-7|-5|\n",
    "\n",
    "- 수식적으로 단순히 '오차 = 실제값 - 예측값' 이라고 정의한 후에 모든 오차를 더하면 음수 오차도 있고, 양수 오차도 있으므로 오차의 절대적인 크기를 구할 수가 없습니다. \n",
    "- 그래서 모든 오차를 제곱하여 더하는 방법을 사용합니다. \n",
    "- 다시 말해 위의 그림에서의 모든 점과 직선 사이의 ↕ 거리를 제곱하고 모두 더합니다. \n",
    "- 이를 수식으로 표현하면 아래와 같습니다. 단, 여기서 n은 갖고 있는 데이터의 개수를 의미합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2 = (-2)^2 + 10^2 + (-7)^2 + (-5)^2 = 178\n",
    "\\end{equation*}\n",
    "\n",
    "- 이때 데이터의 개수인 n으로 나누면, 오차의 제곱합에 대한 평균을 구할 수 있는데 이를 평균 제곱 오차(Mean Squered Error, MSE)라고 합니다. 수식은 아래와 같습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2 = 178 / 4 = 44.5\n",
    "\\end{equation*}\n",
    "\n",
    "- y=13x+1 의 예측값과 실제값의 평균 제곱 오차의 값은 44.5입니다. 평균 제곱 오차의 값을 최소값으로 만드는 W와 b를 찾아내는 것이 정답인 직선을 찾아내는 일입니다. 평균 제곱 오차를 W와 b에 의한 비용 함수(Cost function)로 재정의해보면 다음과 같습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    cost( W, b ) = \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2\n",
    "\\end{equation*}\n",
    "\n",
    "- 모든 점들과의 오차가 클 수록 평균 제곱 오차는 커지며, 오차가 작아질 수록 평균 제곱 오차는 작아집니다. \n",
    "- 그러므로 이 평균 최곱 오차. 즉, Cost(W,b)를 최소가 되게 만드는 W와 b를 구하면 결과적으로 y와 x의 관계를 가장 잘 나타내는 직선을 그릴 수 있습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W,b \\rightarrow minimize cost( W, b )\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 옵티마이저(Optimizer) : 경사하강법(Gradient Descent)\n",
    "\n",
    "- 선형 회귀를 포함한 수많은 머신 러닝 학습은 결국 비용 함수를 최소화하는 매개 변수인 W와 b을 찾기 위한 작업을 수행합니다. 이때 사용되는 알고리즘을 옵티마이저(Optimizer) 또는 최적화 알고리즘이라고 부릅니다.\n",
    "\n",
    "\n",
    "- 그리고 이 옵티마이저를 통해 적절한 W와 b를 찾아내는 과정을 머신 러닝에서 학습(training)이라고 부릅니다. \n",
    "- 여기서는 가장 기본적인 옵티마이저 알고리즘인 경사 하강법(Gradient Descent)에 대해서 배웁니다.\n",
    "\n",
    "\n",
    "- 경사 하강법을 이해하기 위해서 cost와 기울기 W와의 관계를 이해해보겠습니다. \n",
    "- W는 머신 러닝 용어로는 가중치라고 불리지만, 직선의 방정식 관점에서 보면 직선의 기울기를 의미하고 있습니다.\n",
    "- 아래의 그래프는 기울기 W가 지나치게 높거나, 낮을 때 어떻게 오차가 커지는 보여줍니다.\n",
    "\n",
    "![alt text]( w_line.png )\n",
    "\n",
    "- 위의 그림에서 주황색선은 기울기 W가 20일 때, 초록색선은 기울기 W가 1일 때를 보여줍니다. \n",
    "- 각각 y=20x, y=x에 해당되는 직선입니다. \n",
    "- ↕는 각 점에서의 실제값과 두 직선의 예측값과의 오차를 보여줍니다. \n",
    "- 이는 앞서 예측에 사용했던 y=13x+1 직선보다 확연히 큰 오차값들입니다. \n",
    "- 즉, 기울기가 지나치게 크면 실제값과 예측값의 오차가 커지고, 기울기가 지나치게 작아도 실제값과 예측값의 오차가 커집니다. \n",
    "- 사실 b 또한 마찬가지인데 b가 지나치게 크거나 작으면 오차가 커집니다.\n",
    "\n",
    "- 설명의 편의를 위해 편향 b가 없이 단순히 가중치 W만을 사용한 y=Wx라는 가설 H(x)를 가지고, 경사 하강법을 수행한다고 해보겠습니다. 비용 함수의 값 cost(W)는 cost라고 줄여서 표현해보겠습니다. 이에 따라 W와 cost의 관계를 그래프로 표현하면 다음과 같습니다.\n",
    "\n",
    "![alt text]( cost_1.png )\n",
    "\n",
    "- 기울기 W가 무한대로 커지면 커질 수록 cost의 값 또한 무한대로 커지고, \n",
    "- 반대로 기울기 W가 무한대로 작아져도 cost의 값은 무한대로 커집니다. \n",
    "- 위의 그래프에서 cost가 가장 작을 때는 볼록한 부분의 맨 아래 부분입니다. \n",
    "- 기계가 해야할 일은 cost가 가장 최소값을 가지게 하는 W를 찾는 일이므로, \n",
    "- 볼록한 부분의 맨 아래 부분의 W의 값을 찾아야 합니다.\n",
    "![alt text]( cost_2.png )\n",
    "\n",
    "- 기계는 임의의 랜덤값 W값을 정한 뒤에, 맨 아래의 볼록한 부분을 향해 점차 W의 값을 수정해나갑니다.\n",
    "- 위의 그림은 W값이 점차 수정되는 과정을 보여줍니다. \n",
    "- 그리고 이를 가능하게 하는 것이 경사 하강법(Gradient Descent)입니다. \n",
    "- 이를 이해하기 위해서는 고등학교 수학 과정인 미분을 이해해야 합니다. \n",
    "- 경사 하강법은 미분을 배우게 되면 가장 처음 배우게 되는 개념인 한 점에서의 순간 변화율 또는 다른 표현으로는 접선에서의 기울기의 개념을 사용합니다.\n",
    "\n",
    "![alt text]( cost_3.png )\n",
    "\n",
    "- 위의 그림에서 초록색 선은 W가 임의의 값을 가지게 되는 네 가지의 경우에 대해서, \n",
    "- 그래프 상으로 접선의 기울기를 보여줍니다. \n",
    "- 주목할 것은 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기가 점차 작아진다는 점입니다. \n",
    "- 그리고 맨 아래의 볼록한 부분에서는 결국 접선의 기울기가 0이 됩니다. \n",
    "- 그래프 상으로는 초록색 화살표가 수평이 되는 지점입니다.\n",
    "\n",
    "\n",
    "- 즉, cost가 최소화가 되는 지점은 접선의 기울기가 0이 되는 지점이며, \n",
    "- 또한 미분값이 0이 되는 지점입니다. \n",
    "- 경사 하강법의 아이디어는 비용 함수(Cost function)를 미분하여 현재 W에서의 접선의 기울기를 구하고, \n",
    "- 접선의 기울기가 낮은 방향으로 W의 값을 변경하고 \n",
    "- 다시 미분하고 이 과정을 접선의 기울기가 0인 곳을 향해 W의 값을 변경하는 작업을 반복하는 것에 있습니다.\n",
    "\n",
    "\n",
    "- 비용 함수(Cost function)는 아래와 같았습니다.\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "    cost( W, b ) = \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2\n",
    "\\end{equation*}\n",
    "\n",
    "- 이제 비용(cost)를 최소화하는 W를 구하기 위해 W를 업데이트하는 식은 다음과 같습니다. \n",
    "- 이를 접선의 기울기가 0이 될 때까지 반복합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha \\frac{\\mathrm{d}}{\\mathrm{d}w}cost(W)\n",
    "\\end{equation*}\n",
    "\n",
    "위의 식은 현재 W에서의 접선의 기울기와 α와 곱한 값을 현재 W에서 빼서 새로운 W의 값으로 한다는 것을 의미합니다. α는 여기서 학습률(learning rate)이라고 하는데, 우선 α는 생각하지 않고 현재 W에서 현재 W에서의 접선의 기울기를 빼는 행위가 어떤 의미가 있는지 알아보겠습니다.\n",
    "\n",
    "![alt text]( cost_4.png )\n",
    "\n",
    "- 위의 그림은 접선의 기울기가 음수일 때, 0일때, 양수일 때의 경우를 보여줍니다. 접선의 기울기가 음수일 때는 위의 수식이 아래와 같이 표현할 수 있습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha(음수기울기) = W + \\alpha(양수기울기)\n",
    "\\end{equation*}\n",
    "\n",
    "- 즉, 기울기가 음수면 W의 값이 증가하게 되는데 이는 결과적으로 접선의 기울기가 0인 방향으로 W의 값이 조정됩니다. \n",
    "- 만약, 접선의 기울기가 양수라면 위의 수식은 아래와 같이 표현할 수 있습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha(양수기울기)\n",
    "\\end{equation*}\n",
    "\n",
    "- 기울기가 양수면 W의 값이 감소하게 되는데 이는 결과적으로 기울기가 0인 방향으로 W의 값이 조정됩니다. \n",
    "- 결국, 아래의 수식은 접선의 기울기가 음수거나, 양수일 때 모두 접선의 기울기가 0인 방향으로 W의 값을 조정합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha \\frac{\\mathrm{d}}{\\mathrm{d}w}cost(W)\n",
    "\\end{equation*}\n",
    "\n",
    "- 그렇다면 여기서 학습률(learning rate)이라고 말하는 α는 어떤 의미를 가질까요? \n",
    "- 학습률 α은 W의 값을 변경할 때, 얼마나 크게 변경할지를 결정합니다. \n",
    "- 또는 W를 그래프의 한 점으로보고 접선의 기울기가 0일 때까지 경사를 따라 내려간다는 관점에서는 얼마나 큰 폭으로 이동할지를 결정합니다. \n",
    "- 직관적으로 생각하기에 학습률 α의 값을 무작정 크게 하면 접선의 기울기가 최소값이 되는 W를 빠르게 찾을 수 있을 것같지만 그렇지 않습니다.\n",
    "\n",
    "![alt text]( cost_5.png )\n",
    "\n",
    "- 위의 그림은 학습률 α가 지나치게 높은 값을 가질 때, \n",
    "- 접선의 기울기가 0이 되는 W를 찾아가는 것이 아니라 W의 값이 발산하는 상황을 보여줍니다. \n",
    "- 반대로 학습률 α가 지나치게 낮은 값을 가지면 학습 속도가 느려지므로 적당한 α의 값을 찾아내는 것도 중요합니다. \n",
    "\n",
    "- 지금까지는 b는 배제시키고 최적의 W를 찾아내는 것에만 초점을 맞추어 경사 하강법의 원리에 대해서 배웠는데, \n",
    "- 실제 경사 하강법은 W와 b에 대해서 동시에 경사 하강법을 수행하면서 최적의 W와 b의 값을 찾아갑니다.\n",
    "\n",
    "\n",
    "- 가설, 비용 함수, 옵티마이저는 머신 러닝 분야에서 사용되는 포괄적 개념입니다. \n",
    "- 풀고자하는 각 문제에 따라 가설, 비용 함수, 옵티마이저는 전부 다를 수 있으며 선형 회귀에 가장 적합한 비용 함수와 옵티마이저가 알려져있는데 MSE와 경사 하강법이 각각 이에 해당됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 케라스로 구현하는 선형 회귀\n",
    "\n",
    "케라스로 모델을 만드는 기본적인 형식은 다음과 같습니다.\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(1,input_dim=1))\n",
    "\n",
    "Sequential로 model이라는 이름의 모델을 만들고, 그리고 add를 통해 필요한 사항들을 추가해갑니다. \n",
    "첫번째 인자인 1은 출력의 차원을 의미하며, \n",
    "두번째 인자인 input_dim은 입력의 차원을 정의하는데 \n",
    "이번 실습과 같이 1개의 실수 x를 가지고 하는 1개의 실수 y를 예측하는 단순 선형 회귀를 구현하는 경우에는 각각 1의 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # Numpy를 임포트\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([1,2,3,4,5,6,7,8,9]) # 공부하는 시간\n",
    "y=np.array([11,22,33,44,53,66,77,87,95]) # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 32ms/sample - loss: 660.8862 - mse: 660.8862\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5798 - mse: 3.5798\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7940 - mse: 3.7940\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.1912 - mse: 3.1912\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.3347 - mse: 1.3347\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.5937 - mse: 2.5937\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9857 - mse: 1.9857\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1979 - mse: 2.1979\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.3156 - mse: 3.3156\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1525 - mse: 2.1525\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.7511 - mse: 0.7511\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.3082 - mse: 1.3082\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.3983 - mse: 1.3983\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.4542 - mse: 2.4542\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 5.3228 - mse: 5.3228\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.9338 - mse: 4.9338\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.4989 - mse: 2.4989\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.0592 - mse: 3.0592\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.3324 - mse: 3.3324\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.8736 - mse: 4.8736\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.6830 - mse: 1.6830  \n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.9727 - mse: 2.9727\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.6386 - mse: 2.6386\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.6775 - mse: 2.6775\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.9889 - mse: 2.9889\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.6062 - mse: 1.6062\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.2475 - mse: 1.2475\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.9108 - mse: 1.9108\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9678 - mse: 1.9678\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 5.7026 - mse: 5.7026\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.5438 - mse: 4.5438\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.6082 - mse: 3.6082\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.9626 - mse: 2.9626\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.1533 - mse: 4.1533\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1661 - mse: 2.1661\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.1736 - mse: 4.1736\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.9305 - mse: 2.9305\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.4990 - mse: 3.4990\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3195 - mse: 2.3195\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.0582 - mse: 1.0582\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2461 - mse: 2.2461\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.4991 - mse: 3.4991\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 0.8242 - mse: 0.8242\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2557 - mse: 2.2557\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.3242 - mse: 1.3242\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1911 - mse: 2.1911\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.7780 - mse: 1.7780\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 5.1502 - mse: 5.1502\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.1141 - mse: 1.1141\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.0076 - mse: 2.0076\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.6220 - mse: 2.6220\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2803 - mse: 2.2803\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.2616 - mse: 3.2616\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1292 - mse: 2.1292\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.9356 - mse: 1.9356\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.2741 - mse: 4.2741\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2744 - mse: 2.2744\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 1.7576 - mse: 1.7576\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.1046 - mse: 3.1046\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3468 - mse: 2.3468\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.0950 - mse: 2.0950\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.1688 - mse: 3.1688\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.8631 - mse: 2.8631\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.4868 - mse: 1.4868\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9066 - mse: 1.9066\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.0347 - mse: 2.0347\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.6033 - mse: 3.6033\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8562 - mse: 3.8562\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.9983 - mse: 0.9983\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.8257 - mse: 1.8257\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.9180 - mse: 3.9180\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2495 - mse: 2.2495\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5322 - mse: 3.5322\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8427 - mse: 2.8427\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8183 - mse: 2.8183\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.6608 - mse: 3.6608\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3316 - mse: 2.3316\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.7489 - mse: 1.7489\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.6754 - mse: 2.6754\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.3586 - mse: 3.3586\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.2889 - mse: 3.2889\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.4998 - mse: 4.4998\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5648 - mse: 3.5648\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 4.0997 - mse: 4.0997\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.1737 - mse: 3.1737\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.8966 - mse: 3.8966\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7984 - mse: 3.7984\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.0074 - mse: 4.0074\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5431 - mse: 3.5431\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3126 - mse: 2.3126\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.6917 - mse: 3.6917\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9327 - mse: 1.9327\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.9927 - mse: 4.9927\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7805 - mse: 1.7805\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5457 - mse: 1.5457\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.0475 - mse: 3.0475\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8672 - mse: 1.8672\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8859 - mse: 3.8859\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.7801 - mse: 4.7801\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8437 - mse: 2.8437\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.8510 - mse: 0.8510\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.5506 - mse: 2.5506\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.3865 - mse: 1.3865\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.1892 - mse: 3.1892\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.5363 - mse: 4.5363\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1602 - mse: 2.1602\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5366 - mse: 1.5366\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.6775 - mse: 2.6775\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7544 - mse: 1.7544\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.8068 - mse: 0.8068\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1355 - mse: 4.1355\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1688 - mse: 2.1688\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.6967 - mse: 3.6967\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5121 - mse: 1.5121\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4710 - mse: 2.4710\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8998 - mse: 3.8998\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2977 - mse: 2.2977\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.7103 - mse: 5.7103\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1870 - mse: 2.1870\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.2981 - mse: 4.2981\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8104 - mse: 2.8104\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.0073 - mse: 3.0073\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.1171 - mse: 1.1171\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.0144 - mse: 4.0144\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2154 - mse: 2.2154\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1311 - mse: 2.1311\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7831 - mse: 1.7831\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.6040 - mse: 2.6040\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5407 - mse: 1.5407\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7248 - mse: 1.7248\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4767 - mse: 2.4767\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1238 - mse: 4.1238\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.2810 - mse: 3.2810\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 1.7028 - mse: 1.7028\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.6087 - mse: 1.6087  \n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6007 - mse: 4.6007\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3893 - mse: 3.3893\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7867 - mse: 1.7867\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.4223 - mse: 4.4223\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.5573 - mse: 2.5573\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.9690 - mse: 2.9690\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8632 - mse: 2.8633\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.0768 - mse: 2.0768\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8211 - mse: 1.8211\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.7905 - mse: 2.7905\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7239 - mse: 3.7239  \n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4380 - mse: 2.4380\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.0603 - mse: 4.0603\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2906 - mse: 2.2906\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1541 - mse: 4.1541\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.3442 - mse: 4.3442\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3692 - mse: 2.3692\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8697 - mse: 2.8697\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1009 - mse: 4.1009\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8637 - mse: 1.8637\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7056 - mse: 3.7056\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5487 - mse: 1.5487\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.2078 - mse: 1.2078\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2257 - mse: 2.2257\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1794 - mse: 4.1794\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.3084 - mse: 4.3084\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3506 - mse: 2.3506\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.4364 - mse: 2.4364\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.9987 - mse: 5.9987\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8389 - mse: 3.8389\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8000 - mse: 2.8000\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.6384 - mse: 3.6384\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.9750 - mse: 3.9750\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4332 - mse: 2.4332\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7087 - mse: 1.7087\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4512 - mse: 2.4512\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.6126 - mse: 1.6126\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4658 - mse: 2.4658\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.0500 - mse: 1.0500\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.8633 - mse: 2.8633\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1540 - mse: 2.1540\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9154 - mse: 1.9154\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.8309 - mse: 0.8309\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8262 - mse: 2.8262\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.9245 - mse: 4.9245\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.9458 - mse: 3.9458\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9479 - mse: 1.9479\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.9902 - mse: 2.9902\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3036 - mse: 2.3036\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6676 - mse: 4.6676\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2537 - mse: 2.2537\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8560 - mse: 1.8560\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3506 - mse: 3.3506\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.4554 - mse: 1.4554\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.0474 - mse: 2.0474\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7959 - mse: 1.7959\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.7293 - mse: 0.7293\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.5986 - mse: 2.5986\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1617 - mse: 2.1617\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.1692 - mse: 1.1692\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4058 - mse: 2.4058\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6065 - mse: 4.6065\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5863 - mse: 3.5863\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.4073 - mse: 3.4073\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8562 - mse: 3.8562\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2136 - mse: 2.2136  \n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2066 - mse: 2.2066\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.0515 - mse: 3.0515\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.8486 - mse: 5.8486\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7722 - mse: 3.7722\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.4885 - mse: 4.4885\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.5798 - mse: 4.5798\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3344 - mse: 3.3344\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.6032 - mse: 0.6032\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.1106 - mse: 3.1106\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.7220 - mse: 4.7220\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.8134 - mse: 0.8134\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6917 - mse: 4.6917\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.0754 - mse: 2.0754\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.0053 - mse: 4.0053\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.5078 - mse: 4.5078\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.7597 - mse: 2.7597\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.0205 - mse: 1.0205\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.6085 - mse: 2.6085\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.3060 - mse: 3.3060\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9478 - mse: 1.9478\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8435 - mse: 3.8435  \n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4566 - mse: 2.4566\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.9950 - mse: 1.9950\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.4165 - mse: 5.4165\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3181 - mse: 2.3181\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.5896 - mse: 1.5896\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6566 - mse: 4.6566\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.0997 - mse: 1.0997\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.2871 - mse: 4.2871\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.2963 - mse: 3.2963\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.1589 - mse: 3.1589\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8979 - mse: 2.8979\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8266 - mse: 1.8266\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.7428 - mse: 2.7428\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8650 - mse: 3.8650\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.6849 - mse: 4.6849  \n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 984us/sample - loss: 1.9536 - mse: 1.9536\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 862us/sample - loss: 4.0496 - mse: 4.0496\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 966us/sample - loss: 0.9101 - mse: 0.9101\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2843 - mse: 2.2843\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8816 - mse: 1.8816\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.2255 - mse: 1.2255\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.9951 - mse: 3.9951\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7956 - mse: 1.7956\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.5020 - mse: 0.5020\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.5732 - mse: 2.5732\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4603 - mse: 2.4603\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.2655 - mse: 5.2655\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.3141 - mse: 4.3141\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.7660 - mse: 2.7660\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.9791 - mse: 2.9791\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.1773 - mse: 4.1773\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7193 - mse: 1.7193\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8333 - mse: 3.8333\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.2263 - mse: 1.2263\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8657 - mse: 1.8657\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5298 - mse: 3.5298\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5433 - mse: 3.5433\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.8458 - mse: 2.8458  \n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.9957 - mse: 0.9957\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.2185 - mse: 4.2185\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.7372 - mse: 1.7372  \n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3612 - mse: 3.3612\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.4345 - mse: 3.4345\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.0774 - mse: 5.0774\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3392 - mse: 2.3392\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.7987 - mse: 3.7987\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.9478 - mse: 2.9478\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1773 - mse: 2.1773\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.4162 - mse: 1.4162\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 0.7303 - mse: 0.7303\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.7939 - mse: 2.7939\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.9975 - mse: 3.9975\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3591 - mse: 2.3591\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3540 - mse: 3.3540\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2314 - mse: 2.2314\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 3.2773 - mse: 3.2773\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.3775 - mse: 3.3775\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.8437 - mse: 3.8437\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.6881 - mse: 2.6881\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.5262 - mse: 2.5262\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.6254 - mse: 1.6254\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.2217 - mse: 4.2217\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.9350 - mse: 4.9350\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5372 - mse: 3.5372\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 1.8421 - mse: 1.8421\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.1260 - mse: 3.1260\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.7416 - mse: 2.7416\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 4.2318 - mse: 4.2318\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4165 - mse: 2.4165\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.0683 - mse: 3.0683  \n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4816 - mse: 2.4816\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5238 - mse: 3.5238\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.2090 - mse: 3.2090\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2329 - mse: 2.2329\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 5.2090 - mse: 5.2090\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 3.5353 - mse: 3.5353\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.9292 - mse: 2.9292\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
    "model.compile(optimizer=sgd ,loss='mean_squared_error',metrics=['mse'], shuffle=False)\n",
    "# sgd는 경사 하강법을 의미.\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "history = model.fit(X,y, batch_size=1, epochs=300)\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 공부한 시간을 x, 각 공부한 시간에 따른 성적을 y라고 해봅시다. \n",
    "activation은 어떤 함수를 사용할 것인지를 의미하는데 선형 회귀를 사용할 경우에는 linear라고 기재합니다.\n",
    "\n",
    "옵티마이저로는 경사 하강법의 일종인 확률적 경사 하강법을 사용하였으며, 학습률은 0.01로 정하였습니다. 손실 함수로는 평균 제곱 오차를 사용합니다. 그리고 전체 데이터에 대한 훈련 횟수는 300으로 합니다.\n",
    "\n",
    "전체 데이터에 대한 훈련 횟수는 300으로 하였지만, \n",
    "어느 순간 오차가 더 이상 줄어들지 않는데 이는 오차를 최소화하는 가중치 W와 b를 찾았기 때문으로 추정이 가능합니다. \n",
    "이제 최종적으로 선택된 오차를 최소화하는 직선을 그래프로 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1013.9819663078524, 3.0453299039767847, 2.047233769670129, 2.884160310288684, 1.9825340856591032, 2.6170949597791253, 2.07392959545056, 3.1928491364750595, 2.078982360479939, 0.9179378252010792, 3.2929561442385116, 1.8090393882529396, 4.057710765453521, 3.3430550032191806, 3.3727282409866652, 2.534385420382023, 3.1775799517506838, 5.226963181048632, 4.350931403537591, 2.0655477546000234, 4.267679619636813, 4.026429238418738, 4.070757996290922, 3.914791131599082, 3.95629906323221, 3.3938972673689327, 4.400475448514852, 2.4054744736187987, 4.138631676634152, 3.9811141970567405, 3.8773058628107213, 1.0513321398239996, 1.2246255707270595, 4.010370834006204, 1.6916432635237773, 3.5997544574654765, 0.7767234268701739, 3.938254221032063, 3.5251800222322345, 2.0865473257791667, 2.448992193598921, 3.3433957725420544, 4.081801957554287, 3.853778258683936, 1.1721168491575453, 2.2437153372706637, 6.589483781982886, 3.5497444859809346, 1.8064843630062468, 4.205375358876255, 2.1835426493651338, 2.9553998315499888, 2.081799773939161, 1.3450891127447702, 3.8035476522054523, 2.449657997323407, 3.4776603221624907, 2.0537462528639785, 2.04192848275933, 2.362242466155698, 2.678978441076146, 4.323754532204475, 2.5395267434068955, 3.1807760331365795, 1.2697243409024344, 1.4017648676203356, 2.709372943629407, 3.96820391383436, 4.167992979495062, 4.167673895756404, 2.8399387914962264, 1.856219834751553, 4.126653560333782, 4.5619457097103195, 4.25720668811765, 3.27212439953453, 1.6431863146523635, 4.424626562330458, 1.7190225364433394, 2.96607920455022, 1.652589370296078, 0.8718971974578582, 4.420328896906641, 4.09586524632242, 4.266517083884941, 3.1679648988776736, 1.4080208912491798, 3.1634909299254, 5.055989505787794, 2.0506756926576295, 3.1237850601060524, 4.090753863462144, 1.9656578182346292, 0.821805818265097, 2.4427944969825655, 1.9413073238683864, 4.201125829383575, 2.146656540532907, 1.6710955359869533, 1.190950223374077, 1.8659671296158598, 1.5677657416834134, 1.9485609945323732, 2.7084526216818228, 1.3252018390016422, 3.965178952138457, 2.8507271424104044, 3.700417165954908, 1.5451275350319014, 1.6300999737448163, 2.2431385823422008, 3.4717696524328656, 1.3747664772801929, 2.396821452304721, 4.771550703379843, 1.3863242621947494, 2.350575282238424, 3.380139810654024, 2.2492465601923564, 6.170503876275486, 1.648703898406691, 3.5540261029834963, 2.303566108147303, 2.3056872186975346, 1.9670060260428324, 3.6743397969338627, 3.318122689301769, 4.768316655316287, 3.8057280505955635, 2.1948287387688956, 2.399278909433633, 1.7711192766890034, 2.0601965090673833, 6.845011493812005, 2.4361928425367094, 2.3108930041392646, 3.452550919726491, 3.609125119737453, 2.092201399927338, 1.1724790645724472, 3.2356563387956054, 3.9140040034221277, 2.4572993953091404, 4.955160204424626, 2.028503913846281, 1.6381135050000415, 0.9935590577208333, 0.9789745724863477, 3.278039634331233, 5.372902433439675, 3.2720201619797282, 2.599906884961658, 2.8332928443948426, 2.239730058613026, 3.3150257277819843, 3.6275306112236447, 1.8683489428626165, 3.4202338798592486, 4.040900360792875, 1.884740465010206, 2.052764439748393, 3.479697883956962, 4.5897603583418665, 3.7013528123756663, 1.8947274924980269, 3.036264987455474, 2.9897277098821684, 1.9901089117758803, 2.001900091767311, 1.702789831492636, 1.8931593055474676, 1.9024511389434338, 1.790155139234331, 3.037091023599108, 3.8412026962679295, 2.0692242508133254, 3.7690959512773485, 3.8550339763363204, 1.9367757253348827, 6.028379665015058, 3.7297769030556083, 1.0045824617975287, 0.6046617264962859, 1.9530278668842382, 2.569896622043517, 2.082778300055199, 2.1603400567546487, 2.551839521361722, 1.7989319786429405, 3.7374967289571135, 2.6825572544087968, 2.395897350170546, 2.81328162468142, 4.682409199161662, 4.558732910702626, 1.2951049510803487, 1.5538982705782272, 3.6378174838092594, 1.4274711437109444, 2.9464578218758106, 2.849708199914959, 3.4610166922211647, 3.655653073141972, 2.9132011897034116, 4.129275480492248, 3.3328232090506287, 1.2551589620610077, 1.1963308152432244, 1.574309565178636, 3.9442747780897967, 3.128579695647608, 2.107438695203099, 2.1725178269876375, 4.335741256104989, 4.803655629869253, 2.446579264400902, 3.993176843143172, 3.045434534575583, 2.0152568049314947, 3.8729610883941255, 3.813989462951819, 2.571658054884109, 1.7243357442526355, 3.693201849444045, 2.8593442969852023, 2.784297121067842, 4.7870625460313425, 2.2994217489807247, 2.5292210057377815, 1.4728942072639863, 3.547817132125298, 3.578220345131639, 2.322293960282372, 4.294033459232499, 3.756339040273613, 3.0929578710347414, 1.452704754140642, 2.6362005977167025, 3.5002707533745303, 1.5305693086961076, 2.786778272026115, 4.190694626420736, 2.4736976894653506, 3.9729589409091406, 4.156015442380319, 2.1248373087081642, 2.8701511617336006, 3.2552946044339075, 4.472585908240742, 2.530183536310991, 2.9694703999492855, 1.7576067977481418, 4.14778382906742, 2.810438060331055, 2.9670755733321936, 3.7085659007231393, 1.5445052538481023, 1.0929288768933878, 3.378598647709522, 1.675810146249003, 3.687235561096006, 4.214315861463547, 3.915860094776791, 2.5476623235542015, 1.7823142661816544, 4.795068866676754, 3.081566393892798, 1.097760520875454, 1.9670526087284088, 3.248278131010011, 2.780784066352579, 3.217019526494874, 2.2956827763054104, 4.482694915030152, 1.7211661384337478, 1.8193053588749737, 3.6103289781345262, 4.1252143532037735, 0.965564277747439, 1.6041133128779217, 3.0698709471099495, 3.4387995402018228, 2.8292336355273924, 4.24268104467127, 1.8081688641880949, 0.9947142038080428, 1.14738805198835, 1.0338123057865434, 4.384302108445102, 3.512024051613278, 1.7039598756366305, 2.0261504534218044, 2.0253790448833673, 4.23985961990224, 4.07847744681769, 2.9751121333489814, 2.0776711276008024, 1.2893141065206792, 3.831851282467445, 1.6832368293156226]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])\n",
    "#print(history.history['acc'])\n",
    "#print(hist.history['val_loss'])\n",
    "#print(hist.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss = history_dict[ 'loss' ]\n",
    "#val_loss = history_dict[ 'val_loss' ]\n",
    "\n",
    "epochs = range( 1, len( loss ) + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( epochs, loss, 'b', label = 'Training loss' ) # 'bo' 파란색 점\n",
    "#plt.plot( epochs, val_loss, 'b', label = 'Training loss' ) # 'bo' 파란색 실선\n",
    "plt.title( 'Training and validation loss' )\n",
    "plt.xlabel( 'Epochs' )\n",
    "plt.ylabel( 'Loss' )\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe1921f0f90>,\n",
       " <matplotlib.lines.Line2D at 0x7fe1921fb1d0>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, model.predict(X), 'b', X,y, 'k.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프에서 각 점은 우리가 실제 주었던 실제값에 해당되며, \n",
    "직선은 실제값으로부터 오차를 최소화하는 W와 b의 값을 가지는 직선입니다. \n",
    "이제 이 직선을 통해 9시간 30분을 공부하였을 때의 시험 성적을 예측하게 해봅시다. model.predict()은 학습이 완료된 모델이 입력된 데이터에 대해서 어떤 값을 예측하는지를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "9/1 [==============================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 2.5552 - mse: 1.0640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.064021804732167, 1.0640218]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( X, y, batch_size = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.556465]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([9.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  검증 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 1234 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 8 5 6 7 4] 7\n"
     ]
    }
   ],
   "source": [
    "print( X_train, len( X_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 3] 2\n"
     ]
    }
   ],
   "source": [
    "print( X_test, len( X_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 11 87 53 66 77 44] 7\n"
     ]
    }
   ],
   "source": [
    "print( y_train, len( y_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95 33] 2\n"
     ]
    }
   ],
   "source": [
    "print( y_test, len( y_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[ :4 ]\n",
    "partial_X_train = X_train[ 4: ]\n",
    "y_val = y_train[ :4 ]\n",
    "partial_y_train = y_train[ 4: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 1s 167ms/sample - loss: 1537.9954 - mse: 1537.9952 - val_loss: 1.9764 - val_mse: 1.9764\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1709 - mse: 0.1709 - val_loss: 2.5711 - val_mse: 2.5711\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1793 - mse: 0.1793 - val_loss: 2.0993 - val_mse: 2.0993\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 2.0934 - val_mse: 2.0934\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.1716 - mse: 0.1716 - val_loss: 1.8000 - val_mse: 1.8000\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 22ms/sample - loss: 0.2777 - mse: 0.2777 - val_loss: 2.0817 - val_mse: 2.0817\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 24ms/sample - loss: 0.1973 - mse: 0.1973 - val_loss: 1.9460 - val_mse: 1.9460\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.2264 - mse: 0.2264 - val_loss: 2.5270 - val_mse: 2.5270\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.2345 - mse: 0.2345 - val_loss: 2.5195 - val_mse: 2.5195\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 31ms/sample - loss: 0.1342 - mse: 0.1342 - val_loss: 1.7768 - val_mse: 1.7768\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 36ms/sample - loss: 0.2320 - mse: 0.2320 - val_loss: 1.7720 - val_mse: 1.7720\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.2216 - mse: 0.2216 - val_loss: 1.9214 - val_mse: 1.9214\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.2231 - mse: 0.2231 - val_loss: 2.0434 - val_mse: 2.0434\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.1885 - mse: 0.1885 - val_loss: 1.9109 - val_mse: 1.9109\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.1965 - mse: 0.1965 - val_loss: 1.9058 - val_mse: 1.9058\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1830 - mse: 0.1830 - val_loss: 1.7488 - val_mse: 1.7488\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.2556 - mse: 0.2556 - val_loss: 2.1652 - val_mse: 2.1652\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.2211 - mse: 0.2211 - val_loss: 2.1593 - val_mse: 2.1593\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1743 - mse: 0.1743 - val_loss: 2.0121 - val_mse: 2.0121\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.2222 - mse: 0.2222 - val_loss: 2.1481 - val_mse: 2.1481\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.1763 - mse: 0.1763 - val_loss: 1.8776 - val_mse: 1.8776\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.1760 - mse: 0.1760 - val_loss: 1.7234 - val_mse: 1.7234\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1526 - mse: 0.1526 - val_loss: 2.4262 - val_mse: 2.4262\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.2205 - mse: 0.2205 - val_loss: 2.1273 - val_mse: 2.1273\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.1342 - mse: 0.1342 - val_loss: 1.7124 - val_mse: 1.7124\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 1.7081 - val_mse: 1.7081\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.2011 - mse: 0.2011 - val_loss: 1.8515 - val_mse: 1.8515\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.1990 - mse: 0.1990 - val_loss: 2.3935 - val_mse: 2.3935\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.2062 - mse: 0.2062 - val_loss: 2.3868 - val_mse: 2.3868\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 2.0947 - val_mse: 2.0947\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.1290 - mse: 0.1290 - val_loss: 1.6879 - val_mse: 1.6879\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.1946 - mse: 0.1946 - val_loss: 1.8292 - val_mse: 1.8292\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.1959 - mse: 0.1959 - val_loss: 1.9441 - val_mse: 1.9441\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1655 - mse: 0.1655 - val_loss: 1.8201 - val_mse: 1.8201\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 2.0689 - val_mse: 2.0689\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.1561 - mse: 0.1561 - val_loss: 1.9302 - val_mse: 1.9302\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 23ms/sample - loss: 0.1990 - mse: 0.1990 - val_loss: 2.0588 - val_mse: 2.0588\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1810 - mse: 0.1810 - val_loss: 2.3305 - val_mse: 2.3305\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1111 - mse: 0.1111 - val_loss: 1.6577 - val_mse: 1.6577\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.2226 - mse: 0.2226 - val_loss: 1.9125 - val_mse: 1.9125\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1582 - mse: 0.1582 - val_loss: 1.7913 - val_mse: 1.7913\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1546 - mse: 0.1546 - val_loss: 1.6461 - val_mse: 1.6461\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 2.0301 - val_mse: 2.0301\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1869 - mse: 0.1869 - val_loss: 2.0250 - val_mse: 2.0250\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1473 - mse: 0.1473 - val_loss: 1.8907 - val_mse: 1.8907\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1532 - mse: 0.1532 - val_loss: 1.7716 - val_mse: 1.7716\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1940 - mse: 0.1940 - val_loss: 2.0109 - val_mse: 2.0109\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1480 - mse: 0.1480 - val_loss: 1.7638 - val_mse: 1.7638\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1478 - mse: 0.1478 - val_loss: 1.6216 - val_mse: 1.6216\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.2064 - mse: 0.2064 - val_loss: 1.9973 - val_mse: 1.9973\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1453 - mse: 0.1453 - val_loss: 1.7527 - val_mse: 1.7527\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1546 - mse: 0.1546 - val_loss: 1.7488 - val_mse: 1.7488\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1720 - mse: 0.1720 - val_loss: 1.8568 - val_mse: 1.8568\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1633 - mse: 0.1633 - val_loss: 2.2391 - val_mse: 2.2391\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1739 - mse: 0.1739 - val_loss: 2.2334 - val_mse: 2.2334\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.1505 - mse: 0.1505 - val_loss: 2.2278 - val_mse: 2.2278\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1462 - mse: 0.1462 - val_loss: 1.7296 - val_mse: 1.7296\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1804 - mse: 0.1804 - val_loss: 1.9603 - val_mse: 1.9603\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1259 - mse: 0.1259 - val_loss: 2.2124 - val_mse: 2.2124\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1237 - mse: 0.1237 - val_loss: 1.8294 - val_mse: 1.8294\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1186 - mse: 0.1186 - val_loss: 2.2034 - val_mse: 2.2034\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1664 - mse: 0.1664 - val_loss: 2.1979 - val_mse: 2.1979\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0952 - mse: 0.0952 - val_loss: 1.5774 - val_mse: 1.5774\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1173 - mse: 0.1173 - val_loss: 2.1905 - val_mse: 2.1905\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1638 - mse: 0.1638 - val_loss: 2.1851 - val_mse: 2.1851\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1387 - mse: 0.1387 - val_loss: 1.7010 - val_mse: 1.7010\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1408 - mse: 0.1408 - val_loss: 1.6975 - val_mse: 1.6975\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1566 - mse: 0.1566 - val_loss: 1.8008 - val_mse: 1.8008\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1388 - mse: 0.1388 - val_loss: 1.7969 - val_mse: 1.7969\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1314 - mse: 0.1314 - val_loss: 1.6868 - val_mse: 1.6868\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1508 - mse: 0.1508 - val_loss: 2.1538 - val_mse: 2.1538\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0900 - mse: 0.0900 - val_loss: 1.5514 - val_mse: 1.5514\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1496 - mse: 0.1496 - val_loss: 1.6776 - val_mse: 1.6776\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1480 - mse: 0.1480 - val_loss: 2.1401 - val_mse: 2.1401\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.1127 - mse: 0.1127 - val_loss: 1.7763 - val_mse: 1.7763\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1081 - mse: 0.1081 - val_loss: 2.1317 - val_mse: 2.1317\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.1115 - mse: 0.1115 - val_loss: 1.7703 - val_mse: 1.7703\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1069 - mse: 0.1069 - val_loss: 2.1235 - val_mse: 2.1235\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1279 - mse: 0.1279 - val_loss: 1.6603 - val_mse: 1.6603\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1429 - mse: 0.1429 - val_loss: 2.1141 - val_mse: 2.1141\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 22ms/sample - loss: 0.1481 - mse: 0.1481 - val_loss: 2.1091 - val_mse: 2.1091\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1521 - mse: 0.1521 - val_loss: 1.8676 - val_mse: 1.8676\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0926 - mse: 0.0926 - val_loss: 1.5221 - val_mse: 1.5221\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1035 - mse: 0.1035 - val_loss: 2.0968 - val_mse: 2.0968\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1495 - mse: 0.1495 - val_loss: 1.8576 - val_mse: 1.8576\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0910 - mse: 0.0910 - val_loss: 1.5151 - val_mse: 1.5151\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1639 - mse: 0.1639 - val_loss: 1.8510 - val_mse: 1.8510\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.1125 - mse: 0.1125 - val_loss: 1.7349 - val_mse: 1.7349\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1434 - mse: 0.1434 - val_loss: 1.8437 - val_mse: 1.8437\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1041 - mse: 0.1041 - val_loss: 2.0705 - val_mse: 2.0705\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0802 - mse: 0.0802 - val_loss: 1.5033 - val_mse: 1.5033\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1333 - mse: 0.1333 - val_loss: 1.6233 - val_mse: 1.6233\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1319 - mse: 0.1319 - val_loss: 2.0581 - val_mse: 2.0581\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1191 - mse: 0.1191 - val_loss: 2.0536 - val_mse: 2.0536\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 13ms/sample - loss: 0.1183 - mse: 0.1183 - val_loss: 2.0490 - val_mse: 2.0490\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0991 - mse: 0.0991 - val_loss: 1.7104 - val_mse: 1.7104\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1113 - mse: 0.1113 - val_loss: 1.6092 - val_mse: 1.6092\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1160 - mse: 0.1160 - val_loss: 1.6063 - val_mse: 1.6063\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1152 - mse: 0.1152 - val_loss: 1.6034 - val_mse: 1.6034\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1282 - mse: 0.1282 - val_loss: 1.6974 - val_mse: 1.6974\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1327 - mse: 0.1327 - val_loss: 1.8020 - val_mse: 1.8020\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0822 - mse: 0.0822 - val_loss: 1.4764 - val_mse: 1.4764\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1289 - mse: 0.1289 - val_loss: 1.4739 - val_mse: 1.4739\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.1484 - mse: 0.1484 - val_loss: 1.6852 - val_mse: 1.6852\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0900 - mse: 0.0900 - val_loss: 2.0069 - val_mse: 2.0069\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1100 - mse: 0.1100 - val_loss: 2.0026 - val_mse: 2.0026\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1069 - mse: 0.1069 - val_loss: 1.5819 - val_mse: 1.5819\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.1086 - mse: 0.1086 - val_loss: 1.5792 - val_mse: 1.5792\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0863 - mse: 0.0863 - val_loss: 1.9912 - val_mse: 1.9912\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1274 - mse: 0.1274 - val_loss: 1.7728 - val_mse: 1.7728\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0994 - mse: 0.0994 - val_loss: 1.5718 - val_mse: 1.5718\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1286 - mse: 0.1286 - val_loss: 1.7665 - val_mse: 1.7665\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0981 - mse: 0.0981 - val_loss: 1.5669 - val_mse: 1.5669\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0979 - mse: 0.0979 - val_loss: 1.4496 - val_mse: 1.4496\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1146 - mse: 0.1146 - val_loss: 1.5619 - val_mse: 1.5619\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0966 - mse: 0.0966 - val_loss: 1.4454 - val_mse: 1.4454\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1350 - mse: 0.1350 - val_loss: 1.7511 - val_mse: 1.7511\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1089 - mse: 0.1089 - val_loss: 1.9559 - val_mse: 1.9559\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1201 - mse: 0.1201 - val_loss: 1.7447 - val_mse: 1.7447\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0937 - mse: 0.0937 - val_loss: 1.5497 - val_mse: 1.5497\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1212 - mse: 0.1212 - val_loss: 1.7387 - val_mse: 1.7387\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1060 - mse: 0.1060 - val_loss: 1.9405 - val_mse: 1.9405\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1130 - mse: 0.1130 - val_loss: 1.9366 - val_mse: 1.9366\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0646 - mse: 0.0646 - val_loss: 1.4295 - val_mse: 1.4295\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1282 - mse: 0.1282 - val_loss: 1.7277 - val_mse: 1.7277\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1109 - mse: 0.1109 - val_loss: 1.7247 - val_mse: 1.7247\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0896 - mse: 0.0896 - val_loss: 1.5341 - val_mse: 1.5341\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0895 - mse: 0.0895 - val_loss: 1.4218 - val_mse: 1.4218\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1119 - mse: 0.1119 - val_loss: 1.9161 - val_mse: 1.9161\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1081 - mse: 0.1081 - val_loss: 1.9124 - val_mse: 1.9124\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0789 - mse: 0.0789 - val_loss: 1.6134 - val_mse: 1.6134\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0761 - mse: 0.0761 - val_loss: 1.4147 - val_mse: 1.4147\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0757 - mse: 0.0757 - val_loss: 1.9037 - val_mse: 1.9037\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0921 - mse: 0.0921 - val_loss: 1.9000 - val_mse: 1.9000\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0914 - mse: 0.0914 - val_loss: 1.8964 - val_mse: 1.8964\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0908 - mse: 0.0908 - val_loss: 1.8929 - val_mse: 1.8929\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 13ms/sample - loss: 0.0761 - mse: 0.0761 - val_loss: 1.5998 - val_mse: 1.5998\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 13ms/sample - loss: 0.0734 - mse: 0.0734 - val_loss: 1.4046 - val_mse: 1.4046\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1187 - mse: 0.1187 - val_loss: 1.5949 - val_mse: 1.5949\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 20ms/sample - loss: 0.0720 - mse: 0.0720 - val_loss: 1.8800 - val_mse: 1.8800\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 19ms/sample - loss: 0.0880 - mse: 0.0880 - val_loss: 1.8765 - val_mse: 1.8765\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1003 - mse: 0.1003 - val_loss: 1.8730 - val_mse: 1.8730\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0996 - mse: 0.0996 - val_loss: 1.8696 - val_mse: 1.8696\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0727 - mse: 0.0727 - val_loss: 1.5837 - val_mse: 1.5837\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0701 - mse: 0.0701 - val_loss: 1.3926 - val_mse: 1.3926\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0941 - mse: 0.0941 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0677 - mse: 0.0677 - val_loss: 1.8578 - val_mse: 1.8578\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.1000 - mse: 0.1000 - val_loss: 1.6671 - val_mse: 1.6671\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0761 - mse: 0.0761 - val_loss: 1.5728 - val_mse: 1.5728\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0890 - mse: 0.0890 - val_loss: 1.8479 - val_mse: 1.8479\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0980 - mse: 0.0980 - val_loss: 1.6593 - val_mse: 1.6593\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0764 - mse: 0.0764 - val_loss: 1.4838 - val_mse: 1.4838\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0989 - mse: 0.0989 - val_loss: 1.6544 - val_mse: 1.6544\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0865 - mse: 0.0865 - val_loss: 1.8350 - val_mse: 1.8350\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0954 - mse: 0.0954 - val_loss: 1.6492 - val_mse: 1.6492\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 21ms/sample - loss: 0.0915 - mse: 0.0915 - val_loss: 1.6467 - val_mse: 1.6467\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0739 - mse: 0.0739 - val_loss: 1.4742 - val_mse: 1.4742\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0881 - mse: 0.0881 - val_loss: 1.5527 - val_mse: 1.5527\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0639 - mse: 0.0639 - val_loss: 1.3701 - val_mse: 1.3701\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.1033 - mse: 0.1033 - val_loss: 1.5484 - val_mse: 1.5484\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0826 - mse: 0.0826 - val_loss: 1.8126 - val_mse: 1.8126\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0506 - mse: 0.0506 - val_loss: 1.3658 - val_mse: 1.3658\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0900 - mse: 0.0900 - val_loss: 1.8076 - val_mse: 1.8076\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0869 - mse: 0.0869 - val_loss: 1.8045 - val_mse: 1.8045\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0736 - mse: 0.0736 - val_loss: 1.4601 - val_mse: 1.4601\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0701 - mse: 0.0701 - val_loss: 1.3601 - val_mse: 1.3601\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0876 - mse: 0.0876 - val_loss: 1.7960 - val_mse: 1.7960\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0876 - mse: 0.0876 - val_loss: 1.6189 - val_mse: 1.6189\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0840 - mse: 0.0840 - val_loss: 1.6166 - val_mse: 1.6166\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0662 - mse: 0.0662 - val_loss: 1.5290 - val_mse: 1.5290\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0591 - mse: 0.0591 - val_loss: 1.3531 - val_mse: 1.3531\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0956 - mse: 0.0956 - val_loss: 1.5250 - val_mse: 1.5250\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0764 - mse: 0.0764 - val_loss: 1.7784 - val_mse: 1.7784\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0841 - mse: 0.0841 - val_loss: 1.6053 - val_mse: 1.6053\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0656 - mse: 0.0656 - val_loss: 1.4430 - val_mse: 1.4430\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0559 - mse: 0.0559 - val_loss: 1.7705 - val_mse: 1.7705\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0798 - mse: 0.0798 - val_loss: 1.7676 - val_mse: 1.7676\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0792 - mse: 0.0792 - val_loss: 1.7648 - val_mse: 1.7648\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0671 - mse: 0.0671 - val_loss: 1.4369 - val_mse: 1.4369\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0763 - mse: 0.0763 - val_loss: 1.5102 - val_mse: 1.5102\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0550 - mse: 0.0550 - val_loss: 1.7570 - val_mse: 1.7570\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0445 - mse: 0.0445 - val_loss: 1.3391 - val_mse: 1.3391\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0739 - mse: 0.0739 - val_loss: 1.4311 - val_mse: 1.4311\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0665 - mse: 0.0665 - val_loss: 1.4296 - val_mse: 1.4296\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0528 - mse: 0.0528 - val_loss: 1.7475 - val_mse: 1.7475\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0657 - mse: 0.0657 - val_loss: 1.7448 - val_mse: 1.7448\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0638 - mse: 0.0638 - val_loss: 1.4254 - val_mse: 1.4254\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0518 - mse: 0.0518 - val_loss: 1.7402 - val_mse: 1.7402\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0645 - mse: 0.0645 - val_loss: 1.7376 - val_mse: 1.7376\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0735 - mse: 0.0735 - val_loss: 1.7350 - val_mse: 1.7350\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0730 - mse: 0.0730 - val_loss: 1.7323 - val_mse: 1.7323\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0618 - mse: 0.0618 - val_loss: 1.4183 - val_mse: 1.4183\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0763 - mse: 0.0763 - val_loss: 1.5681 - val_mse: 1.5681\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0454 - mse: 0.0454 - val_loss: 1.3253 - val_mse: 1.3253\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0732 - mse: 0.0732 - val_loss: 1.7229 - val_mse: 1.7229\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0616 - mse: 0.0616 - val_loss: 1.7204 - val_mse: 1.7204\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0405 - mse: 0.0405 - val_loss: 1.3222 - val_mse: 1.3222\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0498 - mse: 0.0498 - val_loss: 1.7169 - val_mse: 1.7169\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0606 - mse: 0.0606 - val_loss: 1.7144 - val_mse: 1.7144\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0691 - mse: 0.0691 - val_loss: 1.7119 - val_mse: 1.7119\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0687 - mse: 0.0687 - val_loss: 1.7094 - val_mse: 1.7094\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0682 - mse: 0.0682 - val_loss: 1.7069 - val_mse: 1.7069\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0390 - mse: 0.0390 - val_loss: 1.3162 - val_mse: 1.3162\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0480 - mse: 0.0480 - val_loss: 1.7036 - val_mse: 1.7036\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0585 - mse: 0.0585 - val_loss: 1.7011 - val_mse: 1.7011\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0689 - mse: 0.0689 - val_loss: 1.5459 - val_mse: 1.5459\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0616 - mse: 0.0616 - val_loss: 1.6962 - val_mse: 1.6962\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0560 - mse: 0.0560 - val_loss: 1.3980 - val_mse: 1.3980\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0534 - mse: 0.0534 - val_loss: 1.3103 - val_mse: 1.3103\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 13ms/sample - loss: 0.0649 - mse: 0.0649 - val_loss: 1.3092 - val_mse: 1.3092\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0740 - mse: 0.0740 - val_loss: 1.5373 - val_mse: 1.5373\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0521 - mse: 0.0521 - val_loss: 1.3931 - val_mse: 1.3931\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0443 - mse: 0.0443 - val_loss: 1.6832 - val_mse: 1.6832\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0552 - mse: 0.0552 - val_loss: 1.6809 - val_mse: 1.6809\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0536 - mse: 0.0536 - val_loss: 1.3896 - val_mse: 1.3896\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0661 - mse: 0.0661 - val_loss: 1.5291 - val_mse: 1.5291\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0620 - mse: 0.0620 - val_loss: 1.5274 - val_mse: 1.5274\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0574 - mse: 0.0574 - val_loss: 1.6721 - val_mse: 1.6721\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0353 - mse: 0.0353 - val_loss: 1.3011 - val_mse: 1.3011\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0627 - mse: 0.0627 - val_loss: 1.6684 - val_mse: 1.6684\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0606 - mse: 0.0606 - val_loss: 1.6662 - val_mse: 1.6662\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0622 - mse: 0.0622 - val_loss: 1.5194 - val_mse: 1.5194\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0474 - mse: 0.0474 - val_loss: 1.4460 - val_mse: 1.4460\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0423 - mse: 0.0423 - val_loss: 1.2966 - val_mse: 1.2966\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0568 - mse: 0.0568 - val_loss: 1.3781 - val_mse: 1.3781\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0408 - mse: 0.0408 - val_loss: 1.6560 - val_mse: 1.6560\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0336 - mse: 0.0336 - val_loss: 1.2943 - val_mse: 1.2943\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0580 - mse: 0.0580 - val_loss: 1.2934 - val_mse: 1.2934\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0554 - mse: 0.0554 - val_loss: 1.3741 - val_mse: 1.3741\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0606 - mse: 0.0606 - val_loss: 1.5076 - val_mse: 1.5076\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0423 - mse: 0.0423 - val_loss: 1.6463 - val_mse: 1.6463\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0565 - mse: 0.0565 - val_loss: 1.6442 - val_mse: 1.6442\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0412 - mse: 0.0412 - val_loss: 1.4337 - val_mse: 1.4337\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0396 - mse: 0.0396 - val_loss: 1.6408 - val_mse: 1.6408\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0473 - mse: 0.0473 - val_loss: 1.3680 - val_mse: 1.3680\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0451 - mse: 0.0451 - val_loss: 1.2871 - val_mse: 1.2871\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0548 - mse: 0.0548 - val_loss: 1.2863 - val_mse: 1.2863\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0560 - mse: 0.0560 - val_loss: 1.6330 - val_mse: 1.6330\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0541 - mse: 0.0541 - val_loss: 1.6310 - val_mse: 1.6310\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0395 - mse: 0.0395 - val_loss: 1.4253 - val_mse: 1.4253\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0379 - mse: 0.0379 - val_loss: 1.6277 - val_mse: 1.6277\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0306 - mse: 0.0306 - val_loss: 1.2828 - val_mse: 1.2828\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0613 - mse: 0.0613 - val_loss: 1.4220 - val_mse: 1.4220\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0534 - mse: 0.0534 - val_loss: 1.4880 - val_mse: 1.4880\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0521 - mse: 0.0521 - val_loss: 1.4865 - val_mse: 1.4865\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0328 - mse: 0.0328 - val_loss: 1.2798 - val_mse: 1.2798\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0367 - mse: 0.0367 - val_loss: 1.6173 - val_mse: 1.6173\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0512 - mse: 0.0512 - val_loss: 1.6153 - val_mse: 1.6153\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0509 - mse: 0.0509 - val_loss: 1.6134 - val_mse: 1.6134\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0440 - mse: 0.0440 - val_loss: 1.6115 - val_mse: 1.6115\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0519 - mse: 0.0519 - val_loss: 1.4785 - val_mse: 1.4785\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0464 - mse: 0.0464 - val_loss: 1.6076 - val_mse: 1.6076\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0431 - mse: 0.0431 - val_loss: 1.6058 - val_mse: 1.6058\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0419 - mse: 0.0419 - val_loss: 1.3498 - val_mse: 1.3498\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0340 - mse: 0.0340 - val_loss: 1.6026 - val_mse: 1.6026\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0486 - mse: 0.0486 - val_loss: 1.6008 - val_mse: 1.6008\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.0421 - mse: 0.0421 - val_loss: 1.5989 - val_mse: 1.5989\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.0276 - mse: 0.0276 - val_loss: 1.2717 - val_mse: 1.2717\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0553 - mse: 0.0553 - val_loss: 1.4042 - val_mse: 1.4042\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0442 - mse: 0.0442 - val_loss: 1.5938 - val_mse: 1.5938\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0487 - mse: 0.0487 - val_loss: 1.4655 - val_mse: 1.4655\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0467 - mse: 0.0467 - val_loss: 1.4641 - val_mse: 1.4641\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0294 - mse: 0.0294 - val_loss: 1.2684 - val_mse: 1.2684\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0462 - mse: 0.0462 - val_loss: 1.2677 - val_mse: 1.2677\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0526 - mse: 0.0526 - val_loss: 1.4606 - val_mse: 1.4606\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0455 - mse: 0.0455 - val_loss: 1.4593 - val_mse: 1.4593\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 18ms/sample - loss: 0.0368 - mse: 0.0368 - val_loss: 1.3386 - val_mse: 1.3386\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0367 - mse: 0.0367 - val_loss: 1.2653 - val_mse: 1.2653\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0318 - mse: 0.0318 - val_loss: 1.5792 - val_mse: 1.5792\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0379 - mse: 0.0379 - val_loss: 1.3364 - val_mse: 1.3364\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0431 - mse: 0.0431 - val_loss: 1.3920 - val_mse: 1.3920\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0311 - mse: 0.0311 - val_loss: 1.5744 - val_mse: 1.5744\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0380 - mse: 0.0380 - val_loss: 1.5727 - val_mse: 1.5727\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0249 - mse: 0.0249 - val_loss: 1.2621 - val_mse: 1.2621\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0431 - mse: 0.0431 - val_loss: 1.2615 - val_mse: 1.2615\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0496 - mse: 0.0496 - val_loss: 1.3873 - val_mse: 1.3873\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0301 - mse: 0.0301 - val_loss: 1.5667 - val_mse: 1.5667\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0437 - mse: 0.0437 - val_loss: 1.4455 - val_mse: 1.4455\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0419 - mse: 0.0419 - val_loss: 1.4443 - val_mse: 1.4443\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0330 - mse: 0.0330 - val_loss: 1.3835 - val_mse: 1.3835\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0295 - mse: 0.0295 - val_loss: 1.2582 - val_mse: 1.2582\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0412 - mse: 0.0412 - val_loss: 1.2576 - val_mse: 1.2576\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0469 - mse: 0.0469 - val_loss: 1.4400 - val_mse: 1.4400\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0330 - mse: 0.0330 - val_loss: 1.3257 - val_mse: 1.3257\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0387 - mse: 0.0387 - val_loss: 1.5543 - val_mse: 1.5543\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0295 - mse: 0.0295 - val_loss: 1.3782 - val_mse: 1.3782\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0331 - mse: 0.0331 - val_loss: 1.3236 - val_mse: 1.3236\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0380 - mse: 0.0380 - val_loss: 1.5499 - val_mse: 1.5499\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0343 - mse: 0.0343 - val_loss: 1.5484 - val_mse: 1.5484\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0225 - mse: 0.0225 - val_loss: 1.2537 - val_mse: 1.2537\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0389 - mse: 0.0389 - val_loss: 1.2532 - val_mse: 1.2532\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 17ms/sample - loss: 0.0386 - mse: 0.0386 - val_loss: 1.2527 - val_mse: 1.2527\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0445 - mse: 0.0445 - val_loss: 1.3720 - val_mse: 1.3720\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0355 - mse: 0.0355 - val_loss: 1.5411 - val_mse: 1.5411\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0322 - mse: 0.0322 - val_loss: 1.3180 - val_mse: 1.3180\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0307 - mse: 0.0307 - val_loss: 1.2508 - val_mse: 1.2508\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 0.0374 - mse: 0.0374 - val_loss: 1.2503 - val_mse: 1.2503\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0371 - mse: 0.0371 - val_loss: 1.2498 - val_mse: 1.2498\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 16ms/sample - loss: 0.0379 - mse: 0.0379 - val_loss: 1.5340 - val_mse: 1.5340\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 15ms/sample - loss: 0.0366 - mse: 0.0366 - val_loss: 1.5325 - val_mse: 1.5325\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "# sgd는 경사 하강법을 의미.\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "history = model.fit(partial_X_train,partial_y_train, batch_size=1, epochs=300, \n",
    "                    validation_data = ( X_val, y_val ) )\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss = history_dict[ 'loss' ]\n",
    "val_loss = history_dict[ 'val_loss' ]\n",
    "\n",
    "epochs = range( 1, len( loss ) + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( epochs, loss, 'b', label = 'Training loss' ) # 'b' 파란색 실선\n",
    "plt.plot( epochs, val_loss, 'r', label = 'Validation loss' ) # 'b' 빨간색 실선\n",
    "plt.title( 'Training and validation loss' )\n",
    "plt.xlabel( 'Epochs' )\n",
    "plt.ylabel( 'Loss' )\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2/1 [============================================================] - 0s 2ms/sample - loss: 3.6944 - mse: 7.0709\n"
     ]
    }
   ],
   "source": [
    "evaluate = model.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.070886671543121, 7.0708866]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.68136 ]\n",
      " [33.243134]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  검증용 데이터 - 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 2 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 77ms/sample - loss: 867.5711 - mse: 867.5711 - val_loss: 4.8118 - val_mse: 4.8118\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 4.0187 - mse: 4.0187 - val_loss: 0.5399 - val_mse: 0.5399\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 2.7123 - mse: 2.7123 - val_loss: 0.4465 - val_mse: 0.4465\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 14ms/sample - loss: 2.1820 - mse: 2.1820 - val_loss: 0.3026 - val_mse: 0.3026\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 14ms/sample - loss: 2.2900 - mse: 2.2900 - val_loss: 0.4073 - val_mse: 0.4073\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 1.9314 - mse: 1.9314 - val_loss: 2.1664 - val_mse: 2.1664\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 2.5755 - mse: 2.5755 - val_loss: 0.2783 - val_mse: 0.2783\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 2.3380 - mse: 2.3380 - val_loss: 0.2436 - val_mse: 0.2436\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 2.0935 - mse: 2.0935 - val_loss: 0.2370 - val_mse: 0.2370\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 2.0887 - mse: 2.0887 - val_loss: 0.4725 - val_mse: 0.4725\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 23ms/sample - loss: 1.9727 - mse: 1.9727 - val_loss: 0.2083 - val_mse: 0.2083\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 14ms/sample - loss: 1.9514 - mse: 1.9514 - val_loss: 0.2624 - val_mse: 0.2624\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 14ms/sample - loss: 1.9380 - mse: 1.9380 - val_loss: 0.2224 - val_mse: 0.2224\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.8271 - mse: 1.8271 - val_loss: 0.1661 - val_mse: 0.1661\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.7294 - mse: 1.7294 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.5218 - mse: 1.5218 - val_loss: 0.2511 - val_mse: 0.2511\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 1.3636 - mse: 1.3636 - val_loss: 2.0685 - val_mse: 2.0685\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 17ms/sample - loss: 1.4050 - mse: 1.4050 - val_loss: 0.3988 - val_mse: 0.3988\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.2138 - mse: 1.2138 - val_loss: 2.1887 - val_mse: 2.1887\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 2.0020 - mse: 2.0020 - val_loss: 0.1800 - val_mse: 0.1800\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.4707 - mse: 1.4707 - val_loss: 0.3970 - val_mse: 0.3970\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 17ms/sample - loss: 0.9711 - mse: 0.9711 - val_loss: 2.6257 - val_mse: 2.6257\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.4619 - mse: 1.4619 - val_loss: 0.1061 - val_mse: 0.1061\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.4194 - mse: 1.4194 - val_loss: 0.2828 - val_mse: 0.2828\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.3543 - mse: 1.3543 - val_loss: 0.2592 - val_mse: 0.2592\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.5221 - mse: 1.5221 - val_loss: 0.2811 - val_mse: 0.2811\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.3848 - mse: 1.3848 - val_loss: 0.0949 - val_mse: 0.0949\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.4432 - mse: 1.4432 - val_loss: 0.1807 - val_mse: 0.1807\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 0.8722 - mse: 0.8722 - val_loss: 2.3332 - val_mse: 2.3332\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.7793 - mse: 1.7793 - val_loss: 0.2062 - val_mse: 0.2062\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.3711 - mse: 1.3711 - val_loss: 0.1619 - val_mse: 0.1619\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.0605 - mse: 1.0605 - val_loss: 1.8854 - val_mse: 1.8854\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 1.1544 - mse: 1.1544 - val_loss: 0.2344 - val_mse: 0.2344\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.2285 - mse: 1.2285 - val_loss: 0.4021 - val_mse: 0.4021\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 0.6624 - mse: 0.6624 - val_loss: 2.7049 - val_mse: 2.7049\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.4936 - mse: 1.4936 - val_loss: 1.7630 - val_mse: 1.7630\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 13ms/sample - loss: 1.4768 - mse: 1.4768 - val_loss: 0.0925 - val_mse: 0.0925\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6408 - mse: 0.6408 - val_loss: 2.5675 - val_mse: 2.5675\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.7387 - mse: 1.7387 - val_loss: 0.2366 - val_mse: 0.2366\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0786 - mse: 1.0786 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1745 - mse: 1.1745 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.6756 - mse: 0.6756 - val_loss: 2.4906 - val_mse: 2.4906\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9668 - mse: 0.9668 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.5794 - mse: 0.5794 - val_loss: 2.5400 - val_mse: 2.5400\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.0200 - mse: 1.0200 - val_loss: 0.3311 - val_mse: 0.3311\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0655 - mse: 1.0655 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9625 - mse: 0.9625 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.1121 - mse: 1.1121 - val_loss: 0.1936 - val_mse: 0.1936\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.0624 - mse: 1.0624 - val_loss: 0.1824 - val_mse: 0.1824\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.1121 - mse: 1.1121 - val_loss: 0.3796 - val_mse: 0.3796\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8955 - mse: 0.8955 - val_loss: 1.7246 - val_mse: 1.7246\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0810 - mse: 1.0810 - val_loss: 1.7438 - val_mse: 1.7438\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8982 - mse: 0.8982 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0607 - mse: 1.0607 - val_loss: 0.2465 - val_mse: 0.2465\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0227 - mse: 1.0227 - val_loss: 0.1460 - val_mse: 0.1460\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8660 - mse: 0.8660 - val_loss: 1.6816 - val_mse: 1.6816\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0212 - mse: 1.0212 - val_loss: 1.7023 - val_mse: 1.7023\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8144 - mse: 0.8144 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0481 - mse: 1.0481 - val_loss: 0.1782 - val_mse: 0.1782\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0091 - mse: 1.0091 - val_loss: 0.2368 - val_mse: 0.2368\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5710 - mse: 0.5710 - val_loss: 2.2674 - val_mse: 2.2674\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1558 - mse: 1.1558 - val_loss: 1.6172 - val_mse: 1.6172\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9417 - mse: 0.9417 - val_loss: 0.4373 - val_mse: 0.4373\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0247 - mse: 1.0247 - val_loss: 0.2002 - val_mse: 0.2002\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.5577 - mse: 0.5577 - val_loss: 2.2567 - val_mse: 2.2567\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9087 - mse: 0.9087 - val_loss: 0.4796 - val_mse: 0.4796\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0289 - mse: 1.0289 - val_loss: 0.1806 - val_mse: 0.1806\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0493 - mse: 1.0493 - val_loss: 0.4936 - val_mse: 0.4936\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7668 - mse: 0.7668 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9450 - mse: 0.9450 - val_loss: 1.7193 - val_mse: 1.7193\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7760 - mse: 0.7760 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.5135 - mse: 0.5135 - val_loss: 2.5333 - val_mse: 2.5333\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.3886 - mse: 1.3886 - val_loss: 0.1372 - val_mse: 0.1372\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0577 - mse: 1.0577 - val_loss: 0.5012 - val_mse: 0.5012\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5729 - mse: 0.5729 - val_loss: 2.4960 - val_mse: 2.4960\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9487 - mse: 0.9487 - val_loss: 2.4062 - val_mse: 2.4062\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9534 - mse: 0.9534 - val_loss: 0.4718 - val_mse: 0.4718\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7809 - mse: 0.7809 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9746 - mse: 0.9746 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9064 - mse: 0.9064 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.5295 - mse: 0.5295 - val_loss: 2.2525 - val_mse: 2.2525\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.2941 - mse: 1.2941 - val_loss: 0.1880 - val_mse: 0.1880\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8082 - mse: 0.8082 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9189 - mse: 0.9189 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9155 - mse: 0.9155 - val_loss: 0.2356 - val_mse: 0.2356\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7993 - mse: 0.7993 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.5124 - mse: 0.5124 - val_loss: 2.5271 - val_mse: 2.5271\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 1.2966 - mse: 1.2966 - val_loss: 0.1145 - val_mse: 0.1145\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8635 - mse: 0.8635 - val_loss: 1.6633 - val_mse: 1.6633\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1012 - mse: 1.1012 - val_loss: 0.1411 - val_mse: 0.1411\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8445 - mse: 0.8445 - val_loss: 1.6904 - val_mse: 1.6904\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8124 - mse: 0.8124 - val_loss: 2.3402 - val_mse: 2.3402\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.2458 - mse: 1.2458 - val_loss: 0.1124 - val_mse: 0.1124\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0515 - mse: 1.0515 - val_loss: 0.5796 - val_mse: 0.5796\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9319 - mse: 0.9319 - val_loss: 0.5650 - val_mse: 0.5650\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9422 - mse: 0.9422 - val_loss: 0.5668 - val_mse: 0.5668\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 0.9409 - mse: 0.9409 - val_loss: 0.5611 - val_mse: 0.5611\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9135 - mse: 0.9135 - val_loss: 0.5771 - val_mse: 0.5771\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8060 - mse: 0.8060 - val_loss: 1.6219 - val_mse: 1.6219\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6491 - mse: 0.6491 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.4892 - mse: 0.4892 - val_loss: 2.5933 - val_mse: 2.5933\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9490 - mse: 0.9490 - val_loss: 0.4711 - val_mse: 0.4711\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8089 - mse: 0.8089 - val_loss: 1.6372 - val_mse: 1.6372\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0779 - mse: 1.0779 - val_loss: 0.1266 - val_mse: 0.1266\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8147 - mse: 0.8147 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5221 - mse: 0.5221 - val_loss: 2.4456 - val_mse: 2.4456\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.2907 - mse: 1.2907 - val_loss: 0.1316 - val_mse: 0.1316\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8551 - mse: 0.8551 - val_loss: 1.6480 - val_mse: 1.6480\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9068 - mse: 0.9068 - val_loss: 0.5570 - val_mse: 0.5570\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5504 - mse: 0.5504 - val_loss: 2.5236 - val_mse: 2.5236\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9736 - mse: 0.9736 - val_loss: 2.3649 - val_mse: 2.3649\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.2312 - mse: 1.2312 - val_loss: 0.1403 - val_mse: 0.1403\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8962 - mse: 0.8962 - val_loss: 0.2917 - val_mse: 0.2917\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.5561 - mse: 0.5561 - val_loss: 2.1769 - val_mse: 2.1769\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1795 - mse: 1.1795 - val_loss: 0.1324 - val_mse: 0.1324\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8972 - mse: 0.8972 - val_loss: 0.2646 - val_mse: 0.2646\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7568 - mse: 0.7568 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9852 - mse: 0.9852 - val_loss: 0.1467 - val_mse: 0.1467\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0324 - mse: 1.0324 - val_loss: 0.6135 - val_mse: 0.6135\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6941 - mse: 0.6941 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1387 - mse: 1.1387 - val_loss: 0.6400 - val_mse: 0.6400\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9269 - mse: 0.9269 - val_loss: 0.1538 - val_mse: 0.1538\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8779 - mse: 0.8779 - val_loss: 1.4094 - val_mse: 1.4094\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9026 - mse: 0.9026 - val_loss: 0.5838 - val_mse: 0.5838\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6967 - mse: 0.6967 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.4731 - mse: 0.4731 - val_loss: 2.6020 - val_mse: 2.6020\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1031 - mse: 1.1031 - val_loss: 1.5385 - val_mse: 1.5385\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7899 - mse: 0.7899 - val_loss: 2.0885 - val_mse: 2.0885\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1849 - mse: 1.1849 - val_loss: 0.1319 - val_mse: 0.1319\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8905 - mse: 0.8905 - val_loss: 0.2470 - val_mse: 0.2470\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9926 - mse: 0.9926 - val_loss: 0.5457 - val_mse: 0.5457\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6846 - mse: 0.6846 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8844 - mse: 0.8844 - val_loss: 0.3422 - val_mse: 0.3422\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8165 - mse: 0.8165 - val_loss: 1.6310 - val_mse: 1.6310\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6416 - mse: 0.6416 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1331 - mse: 1.1331 - val_loss: 0.6675 - val_mse: 0.6675\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9327 - mse: 0.9327 - val_loss: 0.1470 - val_mse: 0.1470\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7837 - mse: 0.7837 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9580 - mse: 0.9580 - val_loss: 1.6459 - val_mse: 1.6459\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8924 - mse: 0.8924 - val_loss: 0.6172 - val_mse: 0.6172\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8365 - mse: 0.8365 - val_loss: 1.2941 - val_mse: 1.2941\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9296 - mse: 0.9296 - val_loss: 0.6079 - val_mse: 0.6079\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9101 - mse: 0.9101 - val_loss: 0.1325 - val_mse: 0.1325\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8550 - mse: 0.8550 - val_loss: 1.6352 - val_mse: 1.6352\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.1000 - mse: 1.1000 - val_loss: 0.2945 - val_mse: 0.2945\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8313 - mse: 0.8313 - val_loss: 1.5689 - val_mse: 1.5689\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6268 - mse: 0.6268 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8862 - mse: 0.8862 - val_loss: 0.3083 - val_mse: 0.3083\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9853 - mse: 0.9853 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9029 - mse: 0.9029 - val_loss: 0.1317 - val_mse: 0.1317\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5493 - mse: 0.5493 - val_loss: 2.0717 - val_mse: 2.0717\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1627 - mse: 1.1627 - val_loss: 0.1174 - val_mse: 0.1174\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8778 - mse: 0.8778 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9245 - mse: 0.9245 - val_loss: 0.1555 - val_mse: 0.1555\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7919 - mse: 0.7919 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9588 - mse: 0.9588 - val_loss: 1.6505 - val_mse: 1.6505\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0280 - mse: 1.0280 - val_loss: 0.1110 - val_mse: 0.1110\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8682 - mse: 0.8682 - val_loss: 1.6267 - val_mse: 1.6267\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9318 - mse: 0.9318 - val_loss: 0.5852 - val_mse: 0.5852\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9428 - mse: 0.9428 - val_loss: 0.5346 - val_mse: 0.5346\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9361 - mse: 0.9361 - val_loss: 0.5381 - val_mse: 0.5381\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.8750 - mse: 0.8750 - val_loss: 0.1303 - val_mse: 0.1303\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.8585 - mse: 0.8585 - val_loss: 1.6325 - val_mse: 1.6325\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 1.0579 - mse: 1.0579 - val_loss: 0.1171 - val_mse: 0.1171\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.8640 - mse: 0.8640 - val_loss: 1.6295 - val_mse: 1.6295\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.6597 - mse: 0.6597 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 1.1521 - mse: 1.1521 - val_loss: 0.5473 - val_mse: 0.5473\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.9558 - mse: 0.9558 - val_loss: 0.6325 - val_mse: 0.6325\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.5975 - mse: 0.5975 - val_loss: 2.4393 - val_mse: 2.4393\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.9687 - mse: 0.9687 - val_loss: 2.0550 - val_mse: 2.0550\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.6954 - mse: 0.6954 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.9164 - mse: 0.9164 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 1.1225 - mse: 1.1225 - val_loss: 0.6725 - val_mse: 0.6725\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.9280 - mse: 0.9280 - val_loss: 0.6126 - val_mse: 0.6126\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.6765 - mse: 0.6765 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.5476 - mse: 0.5476 - val_loss: 2.0995 - val_mse: 2.0995\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.9782 - mse: 0.9782 - val_loss: 1.5579 - val_mse: 1.5579\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 1.1078 - mse: 1.1078 - val_loss: 0.2570 - val_mse: 0.2570\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.4910 - mse: 0.4910 - val_loss: 2.5776 - val_mse: 2.5776\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 1.2816 - mse: 1.2816 - val_loss: 0.2849 - val_mse: 0.2849\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 6ms/sample - loss: 0.8902 - mse: 0.8902 - val_loss: 0.3022 - val_mse: 0.3022\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.8174 - mse: 0.8174 - val_loss: 1.6215 - val_mse: 1.6215\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.8178 - mse: 0.8178 - val_loss: 1.9825 - val_mse: 1.9825\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.6647 - mse: 0.6647 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.8920 - mse: 0.8920 - val_loss: 0.2578 - val_mse: 0.2578\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 7ms/sample - loss: 0.7622 - mse: 0.7622 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 1.1214 - mse: 1.1214 - val_loss: 0.6957 - val_mse: 0.6957\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9390 - mse: 0.9390 - val_loss: 0.3254 - val_mse: 0.3254\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8946 - mse: 0.8946 - val_loss: 0.2903 - val_mse: 0.2903\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7228 - mse: 0.7228 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9654 - mse: 0.9654 - val_loss: 1.6439 - val_mse: 1.6439\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9335 - mse: 0.9335 - val_loss: 0.6258 - val_mse: 0.6258\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9296 - mse: 0.9296 - val_loss: 0.2963 - val_mse: 0.2963\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9491 - mse: 0.9491 - val_loss: 0.6774 - val_mse: 0.6774\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6477 - mse: 0.6477 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8879 - mse: 0.8879 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8730 - mse: 0.8730 - val_loss: 0.3231 - val_mse: 0.3231\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 8ms/sample - loss: 0.8906 - mse: 0.8906 - val_loss: 0.3112 - val_mse: 0.3112\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8896 - mse: 0.8896 - val_loss: 0.2582 - val_mse: 0.2582\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8336 - mse: 0.8336 - val_loss: 1.6083 - val_mse: 1.6083\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9408 - mse: 0.9408 - val_loss: 1.2105 - val_mse: 1.2105\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6652 - mse: 0.6652 - val_loss: 2.5307 - val_mse: 2.5307\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9768 - mse: 0.9768 - val_loss: 0.6217 - val_mse: 0.6217\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8077 - mse: 0.8077 - val_loss: 1.6058 - val_mse: 1.6058\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8927 - mse: 0.8927 - val_loss: 1.5650 - val_mse: 1.5650\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8100 - mse: 0.8100 - val_loss: 1.9563 - val_mse: 1.9563\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6376 - mse: 0.6376 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8745 - mse: 0.8745 - val_loss: 0.3321 - val_mse: 0.3321\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7172 - mse: 0.7172 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8713 - mse: 0.8713 - val_loss: 0.3158 - val_mse: 0.3158\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9216 - mse: 0.9216 - val_loss: 0.1552 - val_mse: 0.1552\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5324 - mse: 0.5324 - val_loss: 2.4767 - val_mse: 2.4767\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6618 - mse: 0.6618 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9074 - mse: 0.9074 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1053 - mse: 1.1053 - val_loss: 0.7219 - val_mse: 0.7219\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9357 - mse: 0.9357 - val_loss: 0.3527 - val_mse: 0.3527\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8870 - mse: 0.8870 - val_loss: 0.3167 - val_mse: 0.3167\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8950 - mse: 0.8950 - val_loss: 0.1243 - val_mse: 0.1243\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0347 - mse: 1.0347 - val_loss: 0.7101 - val_mse: 0.7101\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8368 - mse: 0.8368 - val_loss: 1.3084 - val_mse: 1.3084\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8663 - mse: 0.8663 - val_loss: 1.4642 - val_mse: 1.4642\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9159 - mse: 0.9159 - val_loss: 0.5261 - val_mse: 0.5261\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9088 - mse: 0.9088 - val_loss: 0.1568 - val_mse: 0.1568\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9960 - mse: 0.9960 - val_loss: 0.6994 - val_mse: 0.6994\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9362 - mse: 0.9362 - val_loss: 0.3207 - val_mse: 0.3207\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9899 - mse: 0.9899 - val_loss: 0.6719 - val_mse: 0.6719\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9390 - mse: 0.9390 - val_loss: 0.2487 - val_mse: 0.2487\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5422 - mse: 0.5422 - val_loss: 2.4660 - val_mse: 2.4660\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0581 - mse: 1.0581 - val_loss: 1.5130 - val_mse: 1.5130\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.7657 - mse: 0.7657 - val_loss: 2.3900 - val_mse: 2.3900\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0145 - mse: 1.0145 - val_loss: 1.5485 - val_mse: 1.5485\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9316 - mse: 0.9316 - val_loss: 1.2161 - val_mse: 1.2161\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9290 - mse: 0.9290 - val_loss: 0.6476 - val_mse: 0.6476\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9283 - mse: 0.9283 - val_loss: 0.3400 - val_mse: 0.3400\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.7076 - mse: 0.7076 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9095 - mse: 0.9095 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8857 - mse: 0.8857 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9706 - mse: 0.9706 - val_loss: 1.5508 - val_mse: 1.5508\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9090 - mse: 0.9090 - val_loss: 0.5259 - val_mse: 0.5259\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6110 - mse: 0.6110 - val_loss: 2.0887 - val_mse: 2.0887\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1381 - mse: 1.1381 - val_loss: 0.1073 - val_mse: 0.1073\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0267 - mse: 1.0267 - val_loss: 0.6979 - val_mse: 0.6979\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8788 - mse: 0.8788 - val_loss: 0.1272 - val_mse: 0.1272\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.0169 - mse: 1.0169 - val_loss: 0.6876 - val_mse: 0.6876\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8832 - mse: 0.8832 - val_loss: 0.1258 - val_mse: 0.1258\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 0.5254 - mse: 0.5254 - val_loss: 2.4829 - val_mse: 2.4829\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.2029 - mse: 1.2029 - val_loss: 0.1364 - val_mse: 0.1364\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.5368 - mse: 0.5368 - val_loss: 2.4564 - val_mse: 2.4564\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 1.2678 - mse: 1.2678 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8803 - mse: 0.8803 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8123 - mse: 0.8123 - val_loss: 1.6032 - val_mse: 1.6032\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.9407 - mse: 0.9407 - val_loss: 1.2297 - val_mse: 1.2297\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9946 - mse: 0.9946 - val_loss: 0.1410 - val_mse: 0.1410\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8941 - mse: 0.8941 - val_loss: 1.3610 - val_mse: 1.3610\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0644 - mse: 1.0644 - val_loss: 0.2705 - val_mse: 0.2705\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8845 - mse: 0.8845 - val_loss: 0.3113 - val_mse: 0.3113\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9809 - mse: 0.9809 - val_loss: 0.6889 - val_mse: 0.6889\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6242 - mse: 0.6242 - val_loss: 2.4022 - val_mse: 2.4022\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9673 - mse: 0.9673 - val_loss: 0.6137 - val_mse: 0.6137\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8012 - mse: 0.8012 - val_loss: 1.5926 - val_mse: 1.5926\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8926 - mse: 0.8926 - val_loss: 1.5483 - val_mse: 1.5483\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.9242 - mse: 0.9242 - val_loss: 1.2878 - val_mse: 1.2878\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8944 - mse: 0.8944 - val_loss: 1.2310 - val_mse: 1.2310\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8556 - mse: 0.8556 - val_loss: 0.6514 - val_mse: 0.6514\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6190 - mse: 0.6190 - val_loss: 2.1133 - val_mse: 2.1133\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1829 - mse: 1.1829 - val_loss: 0.2701 - val_mse: 0.2701\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8185 - mse: 0.8185 - val_loss: 1.6069 - val_mse: 1.6069\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.6429 - mse: 0.6429 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 1.1470 - mse: 1.1470 - val_loss: 0.6724 - val_mse: 0.6724\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 0.5618 - mse: 0.5618 - val_loss: 2.5525 - val_mse: 2.5525\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9759 - mse: 0.9759 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 9ms/sample - loss: 0.8389 - mse: 0.8389 - val_loss: 1.2720 - val_mse: 1.2720\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0450 - mse: 1.0450 - val_loss: 0.2244 - val_mse: 0.2244\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 12ms/sample - loss: 0.4842 - mse: 0.4842 - val_loss: 2.5893 - val_mse: 2.5893\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.0030 - mse: 1.0030 - val_loss: 2.3267 - val_mse: 2.3267\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.2360 - mse: 1.2360 - val_loss: 0.2294 - val_mse: 0.2294\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9083 - mse: 0.9083 - val_loss: 0.1331 - val_mse: 0.1331\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8674 - mse: 0.8674 - val_loss: 1.6440 - val_mse: 1.6440\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1180 - mse: 1.1180 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8889 - mse: 0.8889 - val_loss: 0.2566 - val_mse: 0.2566\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9144 - mse: 0.9144 - val_loss: 0.1645 - val_mse: 0.1645\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8940 - mse: 0.8940 - val_loss: 0.1359 - val_mse: 0.1359\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8032 - mse: 0.8032 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 1.0048 - mse: 1.0048 - val_loss: 1.3143 - val_mse: 1.3143\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8556 - mse: 0.8556 - val_loss: 1.5769 - val_mse: 1.5769\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.0536 - mse: 1.0536 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.7793 - mse: 0.7793 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8726 - mse: 0.8726 - val_loss: 0.3394 - val_mse: 0.3394\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8941 - mse: 0.8941 - val_loss: 0.2433 - val_mse: 0.2433\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8256 - mse: 0.8256 - val_loss: 1.6032 - val_mse: 1.6032\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 1.1065 - mse: 1.1065 - val_loss: 0.2912 - val_mse: 0.2912\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9967 - mse: 0.9967 - val_loss: 0.6814 - val_mse: 0.6814\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.6627 - mse: 0.6627 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 11ms/sample - loss: 0.8703 - mse: 0.8703 - val_loss: 0.3507 - val_mse: 0.3507\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8855 - mse: 0.8855 - val_loss: 0.3234 - val_mse: 0.3234\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9008 - mse: 0.9008 - val_loss: 0.1289 - val_mse: 0.1289\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9044 - mse: 0.9044 - val_loss: 0.1362 - val_mse: 0.1362\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.9056 - mse: 0.9056 - val_loss: 1.3503 - val_mse: 1.3503\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8949 - mse: 0.8949 - val_loss: 0.5311 - val_mse: 0.5311\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 10ms/sample - loss: 0.8370 - mse: 0.8370 - val_loss: 1.3280 - val_mse: 1.3280\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "# sgd는 경사 하강법을 의미.\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "history = model.fit(X_train,y_train, batch_size=1, epochs=300, \n",
    "                    validation_split = 0.2 )\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss = history_dict[ 'loss' ]\n",
    "val_loss = history_dict[ 'val_loss' ]\n",
    "\n",
    "epochs = range( 1, len( loss ) + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( epochs, loss, 'b', label = 'Training loss' ) # 'b' 파란색 실선\n",
    "plt.plot( epochs, val_loss, 'r', label = 'Validation loss' ) # 'b' 빨간색 실선\n",
    "plt.title( 'Training and validation loss' )\n",
    "plt.xlabel( 'Epochs' )\n",
    "plt.ylabel( 'Loss' )\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97.19637 ]\n",
      " [32.378914]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  나이 X, 키 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array( [ 15.43, 23.01, 5.00, 12.56, 8.67, 7.31, 9.66, 13.64, \n",
    "      14.92, 18.47, 15.48, 22.13, 10.11, 26.95, 5.68, 21.76 ] )\n",
    "y = np.array( [ 170.91, 160.68, 129.00, 159.70, 155.46, 140.56, 153.65, 159.43, \n",
    "      164.70, 169.65, 160.71, 173.29, 159.31, 171.52, 138.96, 165.87 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 1234 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 21ms/sample - loss: 5002520794.7519 - mse: 5002520576.0000\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: 363332944317408.0000 - mse: 363332926177280.0000\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: 26290560761709199360.0000 - mse: 26290561070217035776.0000\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: 1902341446260757081620480.0000 - mse: 1902341235188380433645568.0000\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: 137650329147032404363573198848.0000 - mse: 137650333883642277518777516032.0000\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: 9960164984517963118940105228681216.0000 - mse: 9960164117690603701741415569555456.0000\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: inf - mse: inf                                                                    \n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: inf - mse: inf\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: inf - mse: inf\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: inf - mse: inf\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: inf - mse: inf\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: inf - mse: inf\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: inf - mse: inf\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: inf - mse: inf\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/sample - loss: nan - mse: nan\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/sample - loss: nan - mse: nan\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 5ms/sample - loss: nan - mse: nan\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 3ms/sample - loss: nan - mse: nan\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 3ms/sample - loss: nan - mse: nan\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 176/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 265/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 2ms/sample - loss: nan - mse: nan\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 1ms/sample - loss: nan - mse: nan\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "# sgd는 경사 하강법을 의미.\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "history = model.fit(X_train,y_train, batch_size=1, epochs=300, shuffle=False)\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
